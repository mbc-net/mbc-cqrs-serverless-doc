"use strict";(self.webpackChunkdoc=self.webpackChunkdoc||[]).push([[1339],{2969:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"architecture/step-functions","title":"Step Functions","description":"Learn how to implement AWS Step Functions for workflow orchestration in the MBC CQRS Serverless framework.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/architecture/step-functions.md","sourceDirName":"architecture","slug":"/architecture/step-functions","permalink":"/docs/architecture/step-functions","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"description":"Learn how to implement AWS Step Functions for workflow orchestration in the MBC CQRS Serverless framework."},"sidebar":"tutorialSidebar","previous":{"title":"CDK Infrastructure","permalink":"/docs/architecture/cdk-infrastructure"},"next":{"title":"DynamoDB","permalink":"/docs/dynamodb"}}');var s=t(4848),r=t(8453);const i={sidebar_position:4,description:"Learn how to implement AWS Step Functions for workflow orchestration in the MBC CQRS Serverless framework."},o="Step Functions",c={},l=[{value:"Architecture Overview",id:"architecture-overview",level:2},{value:"State Machines",id:"state-machines",level:2},{value:"Command State Machine",id:"command-state-machine",level:3},{value:"Task State Machine",id:"task-state-machine",level:3},{value:"Import CSV State Machine",id:"import-csv-state-machine",level:3},{value:"System Configuration Example",id:"system-configuration-example",level:2},{value:"Data Flow Example",id:"data-flow-example",level:3},{value:"CDK Implementation Examples",id:"cdk-implementation-examples",level:2},{value:"Complete Command State Machine",id:"complete-command-state-machine",level:3},{value:"Task State Machine with Controlled Concurrency",id:"task-state-machine-with-controlled-concurrency",level:3},{value:"Distributed Map for CSV Import",id:"distributed-map-for-csv-import",level:3},{value:"Event Source Configuration",id:"event-source-configuration",level:3},{value:"Implementation Guide",id:"implementation-guide",level:2},{value:"Step 1: Infrastructure Setup",id:"step-1-infrastructure-setup",level:3},{value:"Step 2: Define Step Function Events",id:"step-2-define-step-function-events",level:3},{value:"Step 3: Implement Event Handlers",id:"step-3-implement-event-handlers",level:3},{value:"Step 4: Configure Event Factory",id:"step-4-configure-event-factory",level:3},{value:"Step 5: Trigger State Machine Execution",id:"step-5-trigger-state-machine-execution",level:3},{value:"Use Cases",id:"use-cases",level:2},{value:"Use Case 1: Data Synchronization",id:"use-case-1-data-synchronization",level:3},{value:"Use Case 2: Batch Task Processing",id:"use-case-2-batch-task-processing",level:3},{value:"Use Case 3: Large-Scale CSV Import",id:"use-case-3-large-scale-csv-import",level:3},{value:"Use Case 4: Async Callback Pattern",id:"use-case-4-async-callback-pattern",level:3},{value:"Callback Patterns with Task Tokens",id:"callback-patterns-with-task-tokens",level:2},{value:"How Callback Patterns Work",id:"how-callback-patterns-work",level:3},{value:"StepFunctionService Implementation",id:"stepfunctionservice-implementation",level:3},{value:"Version-Based Command Chaining",id:"version-based-command-chaining",level:3},{value:"CDK Configuration for Callback Pattern",id:"cdk-configuration-for-callback-pattern",level:3},{value:"Long-Running Workflow Strategies",id:"long-running-workflow-strategies",level:2},{value:"ZIP Import Orchestration",id:"zip-import-orchestration",level:3},{value:"Task Token Propagation for Child Workflows",id:"task-token-propagation-for-child-workflows",level:3},{value:"Workflow Timeout Configuration",id:"workflow-timeout-configuration",level:3},{value:"Integration with Import/Export Patterns",id:"integration-with-importexport-patterns",level:2},{value:"CSV Import Flow",id:"csv-import-flow",level:3},{value:"Progress Tracking with Atomic Counters",id:"progress-tracking-with-atomic-counters",level:3},{value:"Processing Mode Selection",id:"processing-mode-selection",level:3},{value:"Step Functions Context",id:"step-functions-context",level:2},{value:"Error Handling",id:"error-handling",level:2},{value:"Handler-Level Error Handling",id:"handler-level-error-handling",level:3},{value:"Task Error Handling with Continuation",id:"task-error-handling-with-continuation",level:3},{value:"Alarm Publishing",id:"alarm-publishing",level:3},{value:"State machine error handling configuration:",id:"state-machine-error-handling-configuration",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Design Principles",id:"design-principles",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Monitoring",id:"monitoring",level:3},{value:"Related Documentation",id:"related-documentation",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"step-functions",children:"Step Functions"})}),"\n",(0,s.jsx)(e.p,{children:"AWS Step Functions provides serverless workflow orchestration for coordinating distributed applications. In the MBC CQRS Serverless framework, Step Functions are used for:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Long-running workflow orchestration"}),"\n",(0,s.jsx)(e.li,{children:"Saga pattern implementation for distributed transactions"}),"\n",(0,s.jsx)(e.li,{children:"Parallel batch processing with Distributed Map"}),"\n",(0,s.jsx)(e.li,{children:"Asynchronous task coordination with callback patterns"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"architecture-overview",children:"Architecture Overview"}),"\n",(0,s.jsx)(e.mermaid,{value:"flowchart TB\n    subgraph Triggers\n        DDBStream[DynamoDB Streams]\n        SQS[SQS Queue]\n        API[API Gateway]\n    end\n\n    subgraph StepFunctions\n        CommandSM[Command State Machine]\n        TaskSM[Task State Machine]\n        ImportSM[Import CSV State Machine]\n    end\n\n    subgraph Processing\n        Lambda[Lambda Functions]\n        DDB[(DynamoDB)]\n        S3[(S3)]\n    end\n\n    DDBStream --\x3e CommandSM\n    DDBStream --\x3e TaskSM\n    SQS --\x3e ImportSM\n    API --\x3e CommandSM\n\n    CommandSM --\x3e Lambda\n    TaskSM --\x3e Lambda\n    ImportSM --\x3e Lambda\n\n    Lambda --\x3e DDB\n    Lambda --\x3e S3"}),"\n",(0,s.jsx)(e.h2,{id:"state-machines",children:"State Machines"}),"\n",(0,s.jsx)(e.p,{children:"The framework provides three pre-configured state machines:"}),"\n",(0,s.jsx)(e.h3,{id:"command-state-machine",children:"Command State Machine"}),"\n",(0,s.jsx)(e.p,{children:"Handles data synchronization workflows with version control and parallel processing."}),"\n",(0,s.jsx)(e.mermaid,{value:"flowchart LR\n    A[check_version] --\x3e B{version ok?}\n    B --\x3e|Yes| C[set_ttl_command]\n    B --\x3e|No| D[wait_prev_command]\n    D --\x3e C\n    C --\x3e E[history_copy]\n    E --\x3e F[transform_data]\n    F --\x3e G[sync_data_all]\n    G --\x3e H[finish]"}),"\n",(0,s.jsx)(e.p,{children:"Key features:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Version checking"}),": Ensures command ordering and prevents conflicts"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Async callback"}),": Waits for previous commands using task tokens"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Parallel sync"}),": Uses Map state to sync data across multiple targets"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"TTL management"}),": Automatically sets expiration on records"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"task-state-machine",children:"Task State Machine"}),"\n",(0,s.jsx)(e.p,{children:"Executes parallel sub-tasks with controlled concurrency."}),"\n",(0,s.jsx)(e.mermaid,{value:"flowchart LR\n    A[Start] --\x3e B[Map State]\n    B --\x3e C[iteration 1]\n    B --\x3e D[iteration 2]\n    B --\x3e E[iteration N]\n    C --\x3e F[End]\n    D --\x3e F\n    E --\x3e F"}),"\n",(0,s.jsx)(e.p,{children:"Key features:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Controlled concurrency"}),": Limits parallel executions (default: 2)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Status tracking"}),": Real-time task status updates"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Error handling"}),": Automatic failure detection and reporting"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"import-csv-state-machine",children:"Import CSV State Machine"}),"\n",(0,s.jsx)(e.p,{children:"Processes large CSV files using AWS Distributed Map for massive parallelism."}),"\n",(0,s.jsx)(e.mermaid,{value:"flowchart TB\n    A[Start] --\x3e B[Read CSV from S3]\n    B --\x3e C[Distributed Map]\n    C --\x3e D[Batch 1]\n    C --\x3e E[Batch 2]\n    C --\x3e F[Batch N]\n    D --\x3e G[Transform & Validate]\n    E --\x3e G\n    F --\x3e G\n    G --\x3e H[Create Commands]\n    H --\x3e I[End]"}),"\n",(0,s.jsx)(e.p,{children:"Key features:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"S3 native integration"}),": Reads CSV directly from S3"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Batch processing"}),": Groups rows for efficient processing"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"High concurrency"}),": Supports up to 50 concurrent batch processors"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"EXPRESS execution"}),": Uses express workflows for child state machines"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"system-configuration-example",children:"System Configuration Example"}),"\n",(0,s.jsx)(e.p,{children:"The following diagram shows how Step Functions integrate with other AWS services in a typical production environment:"}),"\n",(0,s.jsx)(e.mermaid,{value:'flowchart TB\n    subgraph Client\n        Web[Web Application]\n        Mobile[Mobile App]\n    end\n\n    subgraph APILayer["API Layer"]\n        APIGW[API Gateway]\n        AppSync[AppSync GraphQL]\n    end\n\n    subgraph Compute["Compute Layer"]\n        Lambda[Lambda Function<br/>NestJS Application]\n    end\n\n    subgraph StepFunctions["Step Functions"]\n        CommandSFN[Command Handler<br/>State Machine]\n        TaskSFN[Task Handler<br/>State Machine]\n        ImportSFN[Import CSV<br/>State Machine]\n    end\n\n    subgraph EventDriven["Event-Driven Layer"]\n        SNS[SNS Topics]\n        SQS[SQS Queues]\n        DDBStream[DynamoDB Streams]\n    end\n\n    subgraph Storage["Storage Layer"]\n        DDB[(DynamoDB<br/>Event Store)]\n        S3[(S3<br/>File Storage)]\n        RDS[(RDS Aurora<br/>Read Models)]\n    end\n\n    subgraph Monitoring["Monitoring"]\n        CWLogs[CloudWatch Logs]\n        XRay[X-Ray Tracing]\n        CWAlarms[CloudWatch Alarms]\n    end\n\n    Web --\x3e APIGW\n    Mobile --\x3e APIGW\n    Web --\x3e AppSync\n    APIGW --\x3e Lambda\n    AppSync --\x3e Lambda\n\n    Lambda --\x3e DDB\n    Lambda --\x3e S3\n    Lambda --\x3e RDS\n    Lambda --\x3e SNS\n\n    DDBStream --\x3e Lambda\n    DDB --\x3e DDBStream\n    SNS --\x3e SQS\n    SQS --\x3e Lambda\n\n    Lambda --\x3e CommandSFN\n    Lambda --\x3e TaskSFN\n    Lambda --\x3e ImportSFN\n\n    CommandSFN --\x3e Lambda\n    TaskSFN --\x3e Lambda\n    ImportSFN --\x3e Lambda\n    ImportSFN --\x3e S3\n\n    CommandSFN --\x3e CWLogs\n    TaskSFN --\x3e CWLogs\n    ImportSFN --\x3e CWLogs\n    Lambda --\x3e XRay\n    CWLogs --\x3e CWAlarms'}),"\n",(0,s.jsx)(e.h3,{id:"data-flow-example",children:"Data Flow Example"}),"\n",(0,s.jsx)(e.p,{children:"Here is a typical data flow for a command execution with Step Functions:"}),"\n",(0,s.jsx)(e.mermaid,{value:"sequenceDiagram\n    participant Client\n    participant API as API Gateway\n    participant Lambda\n    participant DDB as DynamoDB\n    participant Stream as DynamoDB Stream\n    participant SFN as Step Functions\n    participant SNS\n    participant SQS\n\n    Client->>API: POST /orders\n    API->>Lambda: Invoke\n    Lambda->>DDB: PutItem (Command)\n    DDB--\x3e>Lambda: Success\n    Lambda--\x3e>API: 202 Accepted\n    API--\x3e>Client: Order Created\n\n    DDB->>Stream: INSERT Event\n    Stream->>Lambda: Trigger\n    Lambda->>SFN: StartExecution\n\n    loop Each State\n        SFN->>Lambda: Invoke (state handler)\n        Lambda->>DDB: Read/Write\n        Lambda--\x3e>SFN: State Output\n    end\n\n    SFN->>Lambda: Finish State\n    Lambda->>SNS: Publish Event\n    SNS->>SQS: Route Message\n    SQS->>Lambda: Process Async"}),"\n",(0,s.jsx)(e.h2,{id:"cdk-implementation-examples",children:"CDK Implementation Examples"}),"\n",(0,s.jsx)(e.h3,{id:"complete-command-state-machine",children:"Complete Command State Machine"}),"\n",(0,s.jsx)(e.p,{children:"The following CDK code shows how to create a complete command handler state machine:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"import * as cdk from 'aws-cdk-lib';\nimport * as sfn from 'aws-cdk-lib/aws-stepfunctions';\nimport * as tasks from 'aws-cdk-lib/aws-stepfunctions-tasks';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as logs from 'aws-cdk-lib/aws-logs';\nimport { Construct } from 'constructs';\n\nexport class CommandStateMachineConstruct extends Construct {\n  public readonly stateMachine: sfn.StateMachine;\n\n  constructor(scope: Construct, id: string, props: { lambdaFunction: lambda.IFunction }) {\n    super(scope, id);\n\n    const { lambdaFunction } = props;\n\n    // Helper function to create Lambda invoke tasks\n    const createLambdaTask = (\n      stateName: string,\n      integrationPattern: sfn.IntegrationPattern = sfn.IntegrationPattern.REQUEST_RESPONSE\n    ) => {\n      const payload: Record<string, any> = {\n        'source': 'step-function',\n        'context.$': '$$',\n        'input.$': '$',\n      };\n\n      // Add task token for callback pattern\n      if (integrationPattern === sfn.IntegrationPattern.WAIT_FOR_TASK_TOKEN) {\n        payload['taskToken'] = sfn.JsonPath.taskToken;\n      }\n\n      return new tasks.LambdaInvoke(this, stateName, {\n        lambdaFunction,\n        payload: sfn.TaskInput.fromObject(payload),\n        stateName,\n        outputPath: '$.Payload[0][0]',\n        integrationPattern,\n        retryOnServiceExceptions: true,\n      });\n    };\n\n    // Define states\n    const fail = new sfn.Fail(this, 'fail', {\n      stateName: 'fail',\n      causePath: '$.cause',\n      errorPath: '$.error',\n    });\n\n    const success = new sfn.Succeed(this, 'success', {\n      stateName: 'success',\n    });\n\n    // Create task states\n    const finish = createLambdaTask('finish').next(success);\n\n    const syncData = createLambdaTask('sync_data');\n\n    // Map state for parallel data sync\n    const syncDataAll = new sfn.Map(this, 'sync_data_all', {\n      stateName: 'sync_data_all',\n      maxConcurrency: 0, // Unlimited concurrency\n      itemsPath: sfn.JsonPath.stringAt('$'),\n    })\n      .itemProcessor(syncData)\n      .next(finish);\n\n    const transformData = createLambdaTask('transform_data').next(syncDataAll);\n    const historyCopy = createLambdaTask('history_copy').next(transformData);\n    const setTtlCommand = createLambdaTask('set_ttl_command').next(historyCopy);\n\n    // Callback pattern for waiting on previous command\n    const waitPrevCommand = createLambdaTask(\n      'wait_prev_command',\n      sfn.IntegrationPattern.WAIT_FOR_TASK_TOKEN\n    ).next(setTtlCommand);\n\n    // Choice state for version checking\n    const checkVersionResult = new sfn.Choice(this, 'check_version_result', {\n      stateName: 'check_version_result',\n    })\n      .when(sfn.Condition.numberEquals('$.result', 0), setTtlCommand)\n      .when(sfn.Condition.numberEquals('$.result', 1), waitPrevCommand)\n      .when(sfn.Condition.numberEquals('$.result', -1), fail)\n      .otherwise(waitPrevCommand);\n\n    const checkVersion = createLambdaTask('check_version').next(checkVersionResult);\n\n    // Create log group\n    const logGroup = new logs.LogGroup(this, 'StateMachineLogGroup', {\n      logGroupName: '/aws/vendedlogs/states/command-handler-logs',\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      retention: logs.RetentionDays.SIX_MONTHS,\n    });\n\n    // Create state machine\n    this.stateMachine = new sfn.StateMachine(this, 'CommandHandlerStateMachine', {\n      stateMachineName: 'command-handler',\n      comment: 'Handles command stream processing with version control',\n      definitionBody: sfn.DefinitionBody.fromChainable(checkVersion),\n      tracingEnabled: true,\n      logs: {\n        destination: logGroup,\n        level: sfn.LogLevel.ALL,\n      },\n    });\n  }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"task-state-machine-with-controlled-concurrency",children:"Task State Machine with Controlled Concurrency"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"export class TaskStateMachineConstruct extends Construct {\n  public readonly stateMachine: sfn.StateMachine;\n\n  constructor(scope: Construct, id: string, props: { lambdaFunction: lambda.IFunction }) {\n    super(scope, id);\n\n    const { lambdaFunction } = props;\n\n    // Iterator task for each item\n    const iteratorTask = new tasks.LambdaInvoke(this, 'iterator', {\n      lambdaFunction,\n      payload: sfn.TaskInput.fromObject({\n        'source': 'step-function',\n        'context.$': '$$',\n        'input.$': '$',\n      }),\n      stateName: 'iterator',\n      outputPath: '$.Payload[0][0]',\n    });\n\n    // Map state with concurrency limit\n    const mapState = new sfn.Map(this, 'TaskMapState', {\n      stateName: 'map_state',\n      maxConcurrency: 2, // Process 2 items at a time\n      inputPath: '$',\n      itemsPath: sfn.JsonPath.stringAt('$'),\n    }).itemProcessor(iteratorTask);\n\n    // Create log group\n    const logGroup = new logs.LogGroup(this, 'TaskLogGroup', {\n      logGroupName: '/aws/vendedlogs/states/task-handler-logs',\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      retention: logs.RetentionDays.SIX_MONTHS,\n    });\n\n    // Create state machine\n    this.stateMachine = new sfn.StateMachine(this, 'TaskHandlerStateMachine', {\n      stateMachineName: 'task-handler',\n      comment: 'Handles parallel task execution with concurrency control',\n      definition: mapState,\n      timeout: cdk.Duration.minutes(15),\n      tracingEnabled: true,\n      logs: {\n        destination: logGroup,\n        level: sfn.LogLevel.ALL,\n      },\n    });\n  }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"distributed-map-for-csv-import",children:"Distributed Map for CSV Import"}),"\n",(0,s.jsx)(e.p,{children:"For processing large CSV files, use Distributed Map which provides native S3 integration:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"import { Map as SfnMap, ProcessorMode, ProcessorConfig, IChainable, JsonPath } from 'aws-cdk-lib/aws-stepfunctions';\n\n// Custom Distributed Map class for S3 CSV processing\nexport class DistributedMap extends SfnMap {\n  public itemReader?: DistributedMapItemReader;\n  public itemBatcher?: DistributedMapItemBatcher;\n  public label?: string;\n\n  public override toStateJson(): object {\n    const mapStateJson = super.toStateJson();\n    return {\n      ...mapStateJson,\n      ItemReader: this.itemReader,\n      ItemBatcher: this.itemBatcher,\n      Label: this.label,\n    };\n  }\n\n  public itemProcessor(processor: IChainable, config: ProcessorConfig = {}): DistributedMap {\n    super.itemProcessor(processor, {\n      ...config,\n      mode: ProcessorMode.DISTRIBUTED,\n    });\n    return this;\n  }\n\n  public setItemReader(itemReader: DistributedMapItemReader): DistributedMap {\n    this.itemReader = itemReader;\n    return this;\n  }\n\n  public setItemBatcher(itemBatcher: DistributedMapItemBatcher): DistributedMap {\n    this.itemBatcher = itemBatcher;\n    return this;\n  }\n\n  public setLabel(label: string): DistributedMap {\n    this.label = label;\n    return this;\n  }\n}\n\n// Usage in your stack\nconst csvRowsHandler = new tasks.LambdaInvoke(this, 'csv_rows_handler', {\n  lambdaFunction,\n  payload: sfn.TaskInput.fromObject({\n    'source': 'step-function',\n    'context.$': '$$',\n    'input.$': '$',\n  }),\n  stateName: 'csv_rows_handler',\n});\n\nconst importCsvDefinition = new DistributedMap(this, 'import-csv', {\n  maxConcurrency: 50, // Process up to 50 batches in parallel\n})\n  .setLabel('import-csv')\n  .setItemReader({\n    Resource: 'arn:aws:states:::s3:getObject',\n    ReaderConfig: {\n      InputType: 'CSV',\n      CSVHeaderLocation: 'FIRST_ROW',\n    },\n    Parameters: {\n      'Bucket.$': '$.bucket',\n      'Key.$': '$.key',\n    },\n  })\n  .setItemBatcher({\n    MaxInputBytesPerBatch: 10,\n    BatchInput: {\n      'Attributes.$': '$',\n    },\n  })\n  .itemProcessor(csvRowsHandler, {\n    executionType: sfn.ProcessorType.EXPRESS, // Use EXPRESS for child executions\n  });\n\nconst importCsvStateMachine = new sfn.StateMachine(this, 'ImportCsvStateMachine', {\n  stateMachineName: 'import-csv',\n  comment: 'Processes large CSV files with distributed batch processing',\n  definitionBody: sfn.DefinitionBody.fromChainable(importCsvDefinition),\n  tracingEnabled: true,\n});\n"})}),"\n",(0,s.jsx)(e.h3,{id:"event-source-configuration",children:"Event Source Configuration"}),"\n",(0,s.jsx)(e.p,{children:"Configure DynamoDB Streams and SQS to trigger Step Functions:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// DynamoDB Stream event source\nconst tableNames = ['tasks', 'commands', 'import_tmp'];\n\nfor (const tableName of tableNames) {\n  const table = dynamodb.Table.fromTableAttributes(this, `${tableName}-table`, {\n    tableArn: `arn:aws:dynamodb:${region}:${account}:table/${prefix}${tableName}`,\n    tableStreamArn: `arn:aws:dynamodb:${region}:${account}:table/${prefix}${tableName}/stream/*`,\n  });\n\n  lambdaFunction.addEventSource(\n    new lambdaEventSources.DynamoEventSource(table, {\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      batchSize: 1,\n      filters: [\n        lambda.FilterCriteria.filter({\n          eventName: lambda.FilterRule.isEqual('INSERT'),\n        }),\n      ],\n    })\n  );\n}\n\n// SQS event sources\nconst queues = ['task-action-queue', 'notification-queue', 'import-action-queue'];\n\nfor (const queueName of queues) {\n  const queue = sqs.Queue.fromQueueArn(\n    this,\n    queueName,\n    `arn:aws:sqs:${region}:${account}:${prefix}${queueName}`\n  );\n\n  lambdaFunction.addEventSource(\n    new lambdaEventSources.SqsEventSource(queue, {\n      batchSize: 1,\n    })\n  );\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"implementation-guide",children:"Implementation Guide"}),"\n",(0,s.jsx)(e.h3,{id:"step-1-infrastructure-setup",children:"Step 1: Infrastructure Setup"}),"\n",(0,s.jsx)(e.p,{children:"The framework automatically provisions Step Functions infrastructure using AWS CDK. Key resources include:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// State machine definition in CDK\nconst commandStateMachine = new sfn.StateMachine(this, 'CommandHandler', {\n  stateMachineName: 'command',\n  definitionBody: sfn.DefinitionBody.fromChainable(definition),\n  timeout: Duration.minutes(15),\n  tracingEnabled: true,\n  logs: {\n    destination: logGroup,\n    level: sfn.LogLevel.ALL,\n  },\n});\n"})}),"\n",(0,s.jsx)(e.h3,{id:"step-2-define-step-function-events",children:"Step 2: Define Step Function Events"}),"\n",(0,s.jsx)(e.p,{children:"Create event classes that extend the base Step Function event:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"import { IEvent } from '@mbc-cqrs-serverless/core';\nimport { StepFunctionsContext } from '@mbc-cqrs-serverless/core';\n\nexport class CustomWorkflowEvent implements IEvent {\n  source: string;\n  context: StepFunctionsContext;\n  input?: WorkflowInput;\n  taskToken?: string;\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"step-3-implement-event-handlers",children:"Step 3: Implement Event Handlers"}),"\n",(0,s.jsx)(e.p,{children:"Create handlers that process Step Function events:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"import { EventHandler, IEventHandler } from '@mbc-cqrs-serverless/core';\nimport { Logger } from '@nestjs/common';\n\n@EventHandler(CustomWorkflowEvent)\nexport class CustomWorkflowHandler implements IEventHandler<CustomWorkflowEvent> {\n  private readonly logger = new Logger(CustomWorkflowHandler.name);\n\n  async execute(event: CustomWorkflowEvent): Promise<StepStateOutput> {\n    const stateName = event.context.State.Name;\n\n    switch (stateName) {\n      case 'initialize':\n        return this.handleInitialize(event);\n      case 'process':\n        return this.handleProcess(event);\n      case 'finalize':\n        return this.handleFinalize(event);\n      default:\n        throw new Error(`Unknown state: ${stateName}`);\n    }\n  }\n\n  private async handleInitialize(event: CustomWorkflowEvent) {\n    // Initialization logic\n    return { status: 'initialized', data: event.input };\n  }\n\n  private async handleProcess(event: CustomWorkflowEvent) {\n    // Processing logic\n    return { status: 'processed' };\n  }\n\n  private async handleFinalize(event: CustomWorkflowEvent) {\n    // Finalization logic\n    return { status: 'completed' };\n  }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"step-4-configure-event-factory",children:"Step 4: Configure Event Factory"}),"\n",(0,s.jsx)(e.p,{children:"Register your Step Function events in the event factory:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"import { EventFactory, IEvent, StepFunctionsEvent } from '@mbc-cqrs-serverless/core';\n\n@EventFactory()\nexport class CustomEventFactory {\n  async transformStepFunction(event: StepFunctionsEvent<any>): Promise<IEvent[]> {\n    const stateMachineName = event.context.StateMachine.Name;\n\n    if (stateMachineName.includes('custom-workflow')) {\n      return [new CustomWorkflowEvent(event)];\n    }\n\n    return [];\n  }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"step-5-trigger-state-machine-execution",children:"Step 5: Trigger State Machine Execution"}),"\n",(0,s.jsx)(e.p,{children:"Start a state machine execution from your service:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"import { StepFunctionService } from '@mbc-cqrs-serverless/core';\nimport { Injectable } from '@nestjs/common';\n\n@Injectable()\nexport class WorkflowService {\n  constructor(private readonly sfnService: StepFunctionService) {}\n\n  async startWorkflow(input: WorkflowInput): Promise<string> {\n    const executionArn = await this.sfnService.startExecution({\n      stateMachineArn: process.env.WORKFLOW_STATE_MACHINE_ARN,\n      input: JSON.stringify(input),\n      name: `workflow-${Date.now()}`,\n    });\n\n    return executionArn;\n  }\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,s.jsx)(e.h3,{id:"use-case-1-data-synchronization",children:"Use Case 1: Data Synchronization"}),"\n",(0,s.jsx)(e.p,{children:"Synchronize data across multiple tables with version control and conflict resolution."}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Scenario"}),": When a command is created, sync the data to multiple read models."]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Trigger: DynamoDB Stream INSERT event\n// Flow: check_version -> set_ttl -> history_copy -> transform -> sync_all -> finish\n\nawait this.commandService.publishAsync(\n  {\n    pk: 'TENANT#tenant1',\n    sk: 'ORDER#order123',\n    id: 'order-uuid',\n    code: 'order123',\n    name: 'Order',\n    type: 'ORDER',\n    version: 1,\n    tenantCode: 'tenant1',\n    attributes: { status: 'confirmed', total: 1000 },\n  },\n  { invokeContext },\n);\n// This triggers the command state machine automatically\n"})}),"\n",(0,s.jsx)(e.h3,{id:"use-case-2-batch-task-processing",children:"Use Case 2: Batch Task Processing"}),"\n",(0,s.jsx)(e.p,{children:"Execute multiple related tasks in parallel with controlled concurrency."}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Scenario"}),": Process multiple items in a batch job with status tracking."]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Create tasks that will be processed by the task state machine\nconst items = [\n  { itemId: 'item1', action: 'process' },\n  { itemId: 'item2', action: 'process' },\n  { itemId: 'item3', action: 'process' },\n];\n\nawait this.taskService.createStepFunctionTask({\n  input: items,\n  taskType: 'batch-processor',\n  tenantCode: 'tenant1',\n}, { invokeContext });\n"})}),"\n",(0,s.jsx)(e.h3,{id:"use-case-3-large-scale-csv-import",children:"Use Case 3: Large-Scale CSV Import"}),"\n",(0,s.jsx)(e.p,{children:"Import millions of rows from CSV files with distributed processing."}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Scenario"}),": Import a large CSV file from S3 with validation and transformation."]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Trigger CSV import via API or direct invocation\nawait this.importService.createCsvImport({\n  s3Bucket: 'my-bucket',\n  s3Key: 'imports/data.csv',\n  tableName: 'products',\n  processingMode: ProcessingMode.STEP_FUNCTION,\n});\n\n// The import-csv state machine will:\n// 1. Read CSV from S3\n// 2. Batch rows (default: 10 per batch)\n// 3. Process up to 50 batches concurrently\n// 4. Transform and validate each row\n// 5. Create import commands\n"})}),"\n",(0,s.jsx)(e.h3,{id:"use-case-4-async-callback-pattern",children:"Use Case 4: Async Callback Pattern"}),"\n",(0,s.jsx)(e.p,{children:"Wait for external events using task tokens."}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Scenario"}),": Wait for approval before proceeding with a workflow."]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:'// In your state machine definition\n{\n  "WaitForApproval": {\n    "Type": "Task",\n    "Resource": "arn:aws:states:::lambda:invoke.waitForTaskToken",\n    "Parameters": {\n      "FunctionName": "${LambdaFunction}",\n      "Payload": {\n        "taskToken.$": "$$.Task.Token",\n        "requestId.$": "$.requestId"\n      }\n    },\n    "Next": "ProcessApproval"\n  }\n}\n\n// In your handler, store the task token\nasync handleWaitForApproval(event: ApprovalEvent) {\n  await this.approvalService.createApprovalRequest({\n    requestId: event.input.requestId,\n    taskToken: event.taskToken, // Store for later callback\n  });\n}\n\n// When approval is received, resume the workflow\nasync approveRequest(requestId: string) {\n  const request = await this.approvalService.getRequest(requestId);\n\n  await this.sfnService.sendTaskSuccess({\n    taskToken: request.taskToken,\n    output: JSON.stringify({ approved: true }),\n  });\n}\n'})}),"\n",(0,s.jsx)(e.h2,{id:"callback-patterns-with-task-tokens",children:"Callback Patterns with Task Tokens"}),"\n",(0,s.jsx)(e.p,{children:"The framework implements callback patterns using AWS Step Functions task tokens for coordinating long-running workflows and waiting for external events."}),"\n",(0,s.jsx)(e.h3,{id:"how-callback-patterns-work",children:"How Callback Patterns Work"}),"\n",(0,s.jsxs)(e.p,{children:["When a Step Function state uses the ",(0,s.jsx)(e.code,{children:"WAIT_FOR_TASK_TOKEN"})," integration pattern, the execution pauses until an external process sends a success or failure response with the task token."]}),"\n",(0,s.jsx)(e.mermaid,{value:"sequenceDiagram\n    participant SFN as Step Functions\n    participant Lambda\n    participant DDB as DynamoDB\n    participant External as External Process\n\n    SFN->>Lambda: Invoke with taskToken\n    Lambda->>DDB: Store taskToken\n    Lambda--\x3e>SFN: Return (execution pauses)\n    Note over SFN: Waiting for callback...\n    External->>Lambda: Trigger callback\n    Lambda->>DDB: Retrieve taskToken\n    Lambda->>SFN: SendTaskSuccess(taskToken)\n    Note over SFN: Execution resumes\n    SFN->>Lambda: Continue to next state"}),"\n",(0,s.jsx)(e.h3,{id:"stepfunctionservice-implementation",children:"StepFunctionService Implementation"}),"\n",(0,s.jsxs)(e.p,{children:["The ",(0,s.jsx)(e.code,{children:"StepFunctionService"})," provides methods for starting executions and resuming paused workflows:"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"import {\n  SFNClient,\n  SendTaskSuccessCommand,\n  StartExecutionCommand,\n} from '@aws-sdk/client-sfn';\n\n@Injectable()\nexport class StepFunctionService {\n  private readonly client: SFNClient;\n\n  constructor(private readonly config: ConfigService) {\n    this.client = new SFNClient({\n      endpoint: config.get<string>('SFN_ENDPOINT'),\n      region: config.get<string>('SFN_REGION'),\n    });\n  }\n\n  // Start a new state machine execution\n  startExecution(arn: string, input: any, name?: string) {\n    return this.client.send(\n      new StartExecutionCommand({\n        stateMachineArn: arn,\n        name: name && name.length <= 80 ? name : undefined,\n        input: JSON.stringify(input),\n      }),\n    );\n  }\n\n  // Resume a paused execution using task token\n  async resumeExecution(taskToken: string, output: any = {}) {\n    // Wrap output in the expected format for Lambda integration\n    const wrappedOutput = {\n      Payload: [[output]],\n    };\n\n    return await this.client.send(\n      new SendTaskSuccessCommand({\n        taskToken: taskToken,\n        output: JSON.stringify(wrappedOutput),\n      }),\n    );\n  }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"version-based-command-chaining",children:"Version-Based Command Chaining"}),"\n",(0,s.jsx)(e.p,{children:"The command state machine uses callback patterns to ensure commands are processed in version order:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Wait for previous command to complete using task token\nprotected async waitConfirmToken(\n  event: DataSyncCommandSfnEvent,\n): Promise<StepFunctionStateInput> {\n  // Store task token in DynamoDB for later callback\n  await this.commandService.updateTaskToken(event.commandKey, event.taskToken);\n  return {\n    result: {\n      token: event.taskToken,\n    },\n  };\n}\n\n// When a command finishes, check if next version is waiting\nprotected async checkNextToken(\n  event: DataSyncCommandSfnEvent,\n): Promise<StepFunctionStateInput> {\n  const nextCommand = await this.commandService.getNextCommand(\n    event.commandKey,\n  );\n\n  if (!nextCommand) {\n    return null; // No next command, chain ends\n  }\n\n  if (nextCommand.taskToken) {\n    // Resume the waiting command\n    try {\n      await this.sfnService.resumeExecution(nextCommand.taskToken, {\n        result: 'resumed_by_prev_version',\n        prevVersion: event.commandRecord.version,\n      });\n    } catch (e) {\n      this.logger.warn(\n        `Could not resume command v${nextCommand.version}: ${e.message}`,\n      );\n    }\n  }\n\n  return null;\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"cdk-configuration-for-callback-pattern",children:"CDK Configuration for Callback Pattern"}),"\n",(0,s.jsx)(e.p,{children:"Configure the state to wait for task token in your CDK stack:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Create a state that waits for callback\nconst waitPrevCommand = new tasks.LambdaInvoke(this, 'wait_prev_command', {\n  lambdaFunction,\n  payload: sfn.TaskInput.fromObject({\n    'input.$': '$',\n    'context.$': '$$',\n    'taskToken': sfn.JsonPath.taskToken, // Include task token in payload\n  }),\n  stateName: 'wait_prev_command',\n  outputPath: '$.Payload[0][0]',\n  // Use WAIT_FOR_TASK_TOKEN integration pattern\n  integrationPattern: sfn.IntegrationPattern.WAIT_FOR_TASK_TOKEN,\n});\n"})}),"\n",(0,s.jsx)(e.h2,{id:"long-running-workflow-strategies",children:"Long-Running Workflow Strategies"}),"\n",(0,s.jsx)(e.p,{children:"The framework provides several strategies for handling long-running workflows:"}),"\n",(0,s.jsx)(e.h3,{id:"zip-import-orchestration",children:"ZIP Import Orchestration"}),"\n",(0,s.jsx)(e.p,{children:"For complex multi-file imports, the framework uses a hierarchical orchestration pattern:"}),"\n",(0,s.jsx)(e.mermaid,{value:'flowchart TB\n    subgraph ZipOrchestrator["ZIP Orchestrator State Machine"]\n        A[Start] --\x3e B[Extract ZIP]\n        B --\x3e C[Map: Process Each CSV]\n        C --\x3e D1[CSV 1: trigger_single_csv_and_wait]\n        C --\x3e D2[CSV 2: trigger_single_csv_and_wait]\n        C --\x3e D3[CSV N: trigger_single_csv_and_wait]\n        D1 --\x3e E[finalize_zip_job]\n        D2 --\x3e E\n        D3 --\x3e E\n        E --\x3e F[End]\n    end\n\n    subgraph CsvStateMachine["CSV State Machine (per file)"]\n        G[csv_loader] --\x3e H[Distributed Map]\n        H --\x3e I[csv_rows_handler x N]\n        I --\x3e J[finalize_parent_job]\n    end\n\n    D1 -.->|taskToken| G\n    J -.->|SendTaskSuccess| D1'}),"\n",(0,s.jsx)(e.h3,{id:"task-token-propagation-for-child-workflows",children:"Task Token Propagation for Child Workflows"}),"\n",(0,s.jsx)(e.p,{children:"When triggering child workflows, the parent stores the task token for later callback:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Trigger a child CSV job and wait for completion\nprivate async triggerSingleCsvJob(event: ZipImportSfnEvent) {\n  const s3Key = event.input?.s3Key || event.input;\n  const { taskToken } = event; // Task token from parent workflow\n  const { masterJobKey, parameters } = event.context.Execution.Input;\n\n  // Create CSV job with stored task token\n  await this.importService.createCsvJobWithTaskToken(\n    {\n      processingMode: ProcessingMode.STEP_FUNCTION,\n      bucket: parameters.bucket,\n      key: s3Key,\n      tenantCode: parameters.tenantCode,\n      tableName: tableName,\n    },\n    taskToken, // Store for callback when CSV processing completes\n    masterJobKey,\n  );\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"workflow-timeout-configuration",children:"Workflow Timeout Configuration"}),"\n",(0,s.jsx)(e.p,{children:"Set appropriate timeouts for long-running workflows:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"const taskStateMachine = new sfn.StateMachine(this, 'task-handler', {\n  stateMachineName: 'task-handler',\n  definition: sfnTaskMapState,\n  timeout: cdk.Duration.minutes(15), // Overall workflow timeout\n  tracingEnabled: true,\n  logs: {\n    destination: logGroup,\n    level: sfn.LogLevel.ALL,\n  },\n});\n"})}),"\n",(0,s.jsx)(e.h2,{id:"integration-with-importexport-patterns",children:"Integration with Import/Export Patterns"}),"\n",(0,s.jsx)(e.p,{children:"The framework integrates Step Functions with the import module for scalable data processing:"}),"\n",(0,s.jsx)(e.h3,{id:"csv-import-flow",children:"CSV Import Flow"}),"\n",(0,s.jsx)(e.p,{children:"The CSV import uses a two-phase approach with Step Functions:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Phase 1: Create import job and trigger Step Function\nasync handleCsvImport(\n  dto: CreateCsvImportDto,\n  options: ICommandOptions,\n): Promise<ImportEntity[] | ImportEntity> {\n  if (dto.processingMode === 'DIRECT') {\n    // Process directly in Lambda (for small files)\n    return this._processCsvDirectly(dto, options);\n  } else {\n    // Create job and let Step Function handle processing\n    return this.createCsvJob(dto, options);\n  }\n}\n\n// Phase 2: Step Function handler processes rows\n@EventHandler(CsvImportSfnEvent)\nexport class CsvImportSfnEventHandler {\n  async handleStepState(event: CsvImportSfnEvent): Promise<any> {\n    if (event.context.State.Name === 'csv_loader') {\n      // Count total rows and initialize job\n      const totalRows = await this.countCsvRows(input);\n      await this.importService.updateImportJob(parentKey, {\n        set: { totalRows },\n      });\n      return this.loadCsv(input);\n    }\n\n    if (event.context.State.Name === 'finalize_parent_job') {\n      return this.finalizeParentJob(event);\n    }\n\n    // Process batch of rows\n    const items = event.input.Items;\n    for (const item of items) {\n      const transformedData = await strategy.transform(item);\n      await strategy.validate(transformedData);\n      await this.importService.createImport(createImportDto, options);\n    }\n  }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"progress-tracking-with-atomic-counters",children:"Progress Tracking with Atomic Counters"}),"\n",(0,s.jsx)(e.p,{children:"The import service uses atomic DynamoDB counters for accurate progress tracking:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Atomically increment progress counters\nasync incrementParentJobCounters(\n  parentKey: DetailKey,\n  childSucceeded: boolean,\n): Promise<ImportEntity> {\n  const countersToIncrement: { [key: string]: number } = {\n    processedRows: 1,\n  };\n  if (childSucceeded) {\n    countersToIncrement.succeededRows = 1;\n  } else {\n    countersToIncrement.failedRows = 1;\n  }\n\n  // Use atomic update expression\n  const command = new UpdateItemCommand({\n    TableName: this.tableName,\n    Key: marshall(parentKey),\n    UpdateExpression: 'SET #processedRows = if_not_exists(#processedRows, :start) + :inc',\n    ExpressionAttributeNames: { '#processedRows': 'processedRows' },\n    ExpressionAttributeValues: marshall({ ':start': 0, ':inc': 1 }),\n    ReturnValues: 'ALL_NEW',\n  });\n\n  const response = await this.dynamoDbService.client.send(command);\n  const updatedEntity = unmarshall(response.Attributes) as ImportEntity;\n\n  // Check if job is complete and update final status\n  if (updatedEntity.totalRows > 0 && updatedEntity.processedRows >= updatedEntity.totalRows) {\n    const finalStatus = updatedEntity.failedRows > 0\n      ? ImportStatusEnum.FAILED\n      : ImportStatusEnum.COMPLETED;\n    await this.updateStatus(parentKey, finalStatus);\n  }\n\n  return updatedEntity;\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"processing-mode-selection",children:"Processing Mode Selection"}),"\n",(0,s.jsx)(e.p,{children:"Choose the appropriate processing mode based on data size:"}),"\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Processing Mode"}),(0,s.jsx)(e.th,{children:"Use Case"}),(0,s.jsx)(e.th,{children:"Max Rows"}),(0,s.jsx)(e.th,{children:"Concurrency"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"DIRECT"})}),(0,s.jsx)(e.td,{children:"Small files, immediate feedback"}),(0,s.jsx)(e.td,{children:"~1,000"}),(0,s.jsx)(e.td,{children:"Single Lambda"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"STEP_FUNCTION"})}),(0,s.jsx)(e.td,{children:"Large files, background processing"}),(0,s.jsx)(e.td,{children:"Millions"}),(0,s.jsx)(e.td,{children:"Up to 50"})]})]})]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Example: Selecting processing mode based on file size\nconst processingMode = estimatedRows > 1000\n  ? ProcessingMode.STEP_FUNCTION\n  : ProcessingMode.DIRECT;\n\nawait importService.handleCsvImport({\n  bucket: 'my-bucket',\n  key: 'data/large-file.csv',\n  tableName: 'products',\n  tenantCode: 'tenant1',\n  processingMode,\n}, { invokeContext });\n"})}),"\n",(0,s.jsx)(e.h2,{id:"step-functions-context",children:"Step Functions Context"}),"\n",(0,s.jsx)(e.p,{children:"Every Step Function event includes context information about the execution:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"interface StepFunctionsContext {\n  Execution: {\n    Id: string;        // Execution ARN\n    Input: object;     // Original input\n    Name: string;      // Execution name\n    RoleArn: string;   // IAM role\n    StartTime: string; // ISO timestamp\n  };\n  State: {\n    EnteredTime: string; // When this state started\n    Name: string;        // Current state name\n    RetryCount: number;  // Retry attempt number\n  };\n  StateMachine: {\n    Id: string;   // State machine ARN\n    Name: string; // State machine name\n  };\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,s.jsx)(e.p,{children:"Implement robust error handling in your state machines:"}),"\n",(0,s.jsx)(e.h3,{id:"handler-level-error-handling",children:"Handler-Level Error Handling"}),"\n",(0,s.jsx)(e.p,{children:"The framework provides built-in error handling patterns for Step Function handlers:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Command event handler with status tracking and error handling\n@Injectable()\nexport class CommandEventHandler {\n  async execute(\n    event: DataSyncCommandSfnEvent,\n  ): Promise<StepFunctionStateInput | StepFunctionStateInput[]> {\n    // Update status to STARTED before processing\n    await this.commandService.updateStatus(\n      event.commandKey,\n      getCommandStatus(event.stepStateName, CommandStatus.STATUS_STARTED),\n      event.commandRecord.requestId,\n    );\n\n    try {\n      const ret = await this.handleStepState(event);\n      // Update status to FINISHED on success\n      await this.commandService.updateStatus(\n        event.commandKey,\n        getCommandStatus(event.stepStateName, CommandStatus.STATUS_FINISHED),\n        event.commandRecord.requestId,\n      );\n      return ret;\n    } catch (error) {\n      // Update status to FAILED and publish alarm on error\n      await this.commandService.updateStatus(\n        event.commandKey,\n        getCommandStatus(event.stepStateName, CommandStatus.STATUS_FAILED),\n        event.commandRecord.requestId,\n      );\n      await this.publishAlarm(event, (error as Error).stack);\n      throw error;\n    }\n  }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"task-error-handling-with-continuation",children:"Task Error Handling with Continuation"}),"\n",(0,s.jsx)(e.p,{children:"For task handlers, the framework supports continuing execution even after errors:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Task handler with error handling that allows workflow continuation\n@EventHandler(StepFunctionTaskEvent)\nexport class TaskSfnEventHandler implements IEventHandler<StepFunctionTaskEvent> {\n  async execute(event: StepFunctionTaskEvent): Promise<any> {\n    const taskKey = event.taskKey;\n\n    try {\n      await this.taskService.updateSubTaskStatus(taskKey, TaskStatusEnum.PROCESSING);\n      const events = await this.eventFactory.transformStepFunctionTask(event);\n      const result = await Promise.all(\n        events.map((event) => this.eventBus.execute(event)),\n      );\n      // Update status to COMPLETED on success\n      await this.taskService.updateSubTaskStatus(taskKey, TaskStatusEnum.COMPLETED, {\n        result,\n      });\n    } catch (error) {\n      // Update status to FAILED and publish alarm, but don't throw\n      this.logger.error(error);\n      await Promise.all([\n        this.taskService.updateSubTaskStatus(taskKey, TaskStatusEnum.FAILED, {\n          error: (error as Error).stack,\n        }),\n        this.taskService.publishAlarm(event, (error as Error).stack),\n      ]);\n      // Note: Error is not re-thrown to allow Step Function to continue\n      // throw error // Uncomment to fail the entire workflow on error\n    }\n  }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"alarm-publishing",children:"Alarm Publishing"}),"\n",(0,s.jsx)(e.p,{children:"The framework publishes alarms to SNS for monitoring and alerting:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-typescript",children:"// Publish alarm notification to SNS topic\nasync publishAlarm(\n  event: DataSyncCommandSfnEvent,\n  errorDetails: any,\n): Promise<void> {\n  const alarm: INotification = {\n    action: 'sfn-alarm',\n    id: `${event.commandKey.pk}#${event.commandKey.sk}`,\n    table: this.options.tableName,\n    pk: event.commandKey.pk,\n    sk: event.commandKey.sk,\n    tenantCode: event.commandKey.pk.substring(\n      event.commandKey.pk.indexOf('#') + 1,\n    ),\n    content: {\n      errorMessage: errorDetails,\n      sfnId: event.context.Execution.Id,\n    },\n  };\n  await this.snsService.publish<INotification>(alarm, this.alarmTopicArn);\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"state-machine-error-handling-configuration",children:"State machine error handling configuration:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-json",children:'{\n  "ProcessStep": {\n    "Type": "Task",\n    "Resource": "${LambdaArn}",\n    "Retry": [\n      {\n        "ErrorEquals": ["States.TaskFailed"],\n        "IntervalSeconds": 2,\n        "MaxAttempts": 3,\n        "BackoffRate": 2\n      }\n    ],\n    "Catch": [\n      {\n        "ErrorEquals": ["States.ALL"],\n        "Next": "HandleError",\n        "ResultPath": "$.error"\n      }\n    ],\n    "Next": "NextStep"\n  }\n}\n'})}),"\n",(0,s.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsx)(e.h3,{id:"design-principles",children:"Design Principles"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Idempotency"}),": Design each state to be safely retryable"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Single Responsibility"}),": Each state should do one thing well"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Timeout Configuration"}),": Set appropriate timeouts for each state"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Logging"}),": Enable comprehensive logging for debugging"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Use Express Workflows"}),": For high-volume, short-duration workflows"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Batch Processing"}),": Group items to reduce state transitions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Concurrency Limits"}),": Set appropriate limits to prevent throttling"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"S3 Integration"}),": Use native S3 integration for large data processing"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"monitoring",children:"Monitoring"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"CloudWatch Metrics"}),": Monitor execution counts, failures, and duration"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"X-Ray Tracing"}),": Enable distributed tracing for debugging"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"CloudWatch Logs"}),": Capture detailed execution logs"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Alarms"}),": Set up alerts for failure rates and execution times"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"related-documentation",children:"Related Documentation"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"/docs/tasks",children:"Task Module"})," - Task management with Step Functions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"/docs/import-export-patterns",children:"Import/Export Patterns"})," - CSV import with Distributed Map"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"/docs/architecture/event-sourcing",children:"Event Sourcing"})," - Event-driven architecture"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"/docs/architecture/cqrs-flow",children:"CQRS Flow"})," - Command and query separation"]}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>i,x:()=>o});var a=t(6540);const s={},r=a.createContext(s);function i(n){const e=a.useContext(r);return a.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:i(n.components),a.createElement(r.Provider,{value:e},n.children)}}}]);