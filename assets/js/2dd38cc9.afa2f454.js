"use strict";(self.webpackChunkdoc=self.webpackChunkdoc||[]).push([[9725],{8056:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"data-migration-patterns","title":"Data Migration Patterns","description":"Learn data migration strategies for cross-tenant operations, schema evolution, and bulk data processing in MBC CQRS Serverless.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/data-migration-patterns.md","sourceDirName":".","slug":"/data-migration-patterns","permalink":"/docs/data-migration-patterns","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":18,"frontMatter":{"sidebar_position":18,"description":"Learn data migration strategies for cross-tenant operations, schema evolution, and bulk data processing in MBC CQRS Serverless."},"sidebar":"tutorialSidebar","previous":{"title":"API Integration Guide","permalink":"/docs/api-integration-guide"},"next":{"title":"Modules","permalink":"/docs/api-reference"}}');var i=t(4848),a=t(8453);const s={sidebar_position:18,description:"Learn data migration strategies for cross-tenant operations, schema evolution, and bulk data processing in MBC CQRS Serverless."},o="Data Migration Patterns",c={},d=[{value:"When to Use This Guide",id:"when-to-use-this-guide",level:2},{value:"Migration Architecture Overview",id:"migration-architecture-overview",level:2},{value:"Tenant Code Normalization Migration",id:"tenant-code-normalization-migration",level:2},{value:"Understanding the Impact",id:"understanding-the-impact",level:3},{value:"Migration Strategy 1: Update DynamoDB Data",id:"strategy-1-update-dynamodb",level:3},{value:"Migration Strategy 2: Update Cognito User Attributes",id:"strategy-2-update-cognito",level:3},{value:"Migration Strategy 3: Dual-Read Approach",id:"strategy-3-dual-read",level:3},{value:"Migration Checklist",id:"migration-checklist",level:3},{value:"RDS Migration",id:"rds-migration",level:3},{value:"Verification Script",id:"verification-script",level:3},{value:"Cross-Tenant Data Migration",id:"cross-tenant-data-migration",level:2},{value:"Pattern 1: Copy Data Between Tenants",id:"pattern-1-copy-data-between-tenants",level:3},{value:"Pattern 2: Bulk Migration with Import Module",id:"pattern-2-bulk-migration-with-import-module",level:3},{value:"Schema Evolution Strategies",id:"schema-evolution-strategies",level:2},{value:"Strategy 1: Backward Compatible Changes",id:"strategy-1-backward-compatible-changes",level:3},{value:"Strategy 2: Data Transformation Migration",id:"strategy-2-data-transformation-migration",level:3},{value:"Strategy 3: Versioned Attributes Pattern",id:"strategy-3-versioned-attributes-pattern",level:3},{value:"Using Import Module for Bulk Operations",id:"using-import-module-for-bulk-operations",level:2},{value:"CSV-Based Bulk Migration",id:"csv-based-bulk-migration",level:3},{value:"Import Process Strategy for Migration",id:"import-process-strategy-for-migration",level:3},{value:"Rollback Procedures",id:"rollback-procedures",level:2},{value:"Event Sourcing Based Rollback",id:"event-sourcing-based-rollback",level:3},{value:"Soft Delete Pattern for Safe Rollback",id:"soft-delete-pattern-for-safe-rollback",level:3},{value:"Data Validation During Migration",id:"data-validation-during-migration",level:2},{value:"Pre-Migration Validation",id:"pre-migration-validation",level:3},{value:"Post-Migration Verification",id:"post-migration-verification",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"1. Always Use Transactions When Possible",id:"1-always-use-transactions-when-possible",level:3},{value:"2. Track Migration Metadata",id:"2-track-migration-metadata",level:3},{value:"3. Implement Idempotent Migrations",id:"3-implement-idempotent-migrations",level:3},{value:"4. Use Batch Processing for Large Datasets",id:"4-use-batch-processing-for-large-datasets",level:3},{value:"5. Create Migration Checkpoints",id:"5-create-migration-checkpoints",level:3},{value:"Related Documentation",id:"related-documentation",level:2}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",input:"input",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"data-migration-patterns",children:"Data Migration Patterns"})}),"\n",(0,i.jsx)(n.p,{children:"This guide covers data migration strategies in MBC CQRS Serverless applications, including cross-tenant data migration, schema evolution, bulk data operations using the Import module, and rollback procedures."}),"\n",(0,i.jsx)(n.h2,{id:"when-to-use-this-guide",children:"When to Use This Guide"}),"\n",(0,i.jsx)(n.p,{children:"Use this guide when you need to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Migrate data between tenants"}),"\n",(0,i.jsx)(n.li,{children:"Evolve data schemas while maintaining compatibility"}),"\n",(0,i.jsx)(n.li,{children:"Perform bulk data operations with the Import module"}),"\n",(0,i.jsx)(n.li,{children:"Implement rollback procedures for failed migrations"}),"\n",(0,i.jsx)(n.li,{children:"Validate data during migration processes"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"migration-architecture-overview",children:"Migration Architecture Overview"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Data Migration Flow                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502   Source  \u2502\u2500\u2500\u2500\u2500>\u2502 Transform \u2502\u2500\u2500\u2500\u2500>\u2502  Target   \u2502               \u2502\n\u2502   \u2502   Data    \u2502     \u2502 & Validate \u2502     \u2502   Data    \u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502          \u2502                   \u2502                    \u2502                      \u2502\n\u2502          \u2502                   \u25bc                    \u2502                      \u2502\n\u2502          \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502                      \u2502\n\u2502          \u2502          \u2502  Import   \u2502              \u2502                      \u2502\n\u2502          \u2502          \u2502  Module   \u2502              \u2502                      \u2502\n\u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502  Strategy \u2502<\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                      \u2502\n\u2502                            \u2502                                             \u2502\n\u2502                            \u25bc                                             \u2502\n\u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502\n\u2502                     \u2502 CommandSvc\u2502\u2500\u2500\u2500\u2500>\u2502  DynamoDB \u2502                 \u2502\n\u2502                     \u2502 (Version) \u2502     \u2502 (History) \u2502                 \u2502\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                                                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(n.h2,{id:"tenant-code-normalization-migration",children:"Tenant Code Normalization Migration"}),"\n",(0,i.jsxs)(n.admonition,{title:"Breaking Change",type:"danger",children:[(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"getUserContext()"})," function normalizes ",(0,i.jsx)(n.code,{children:"tenantCode"})," to lowercase. This is a breaking change that affects data access if your existing data uses uppercase tenant codes in partition keys."]}),(0,i.jsxs)(n.p,{children:["For a complete migration checklist and step-by-step instructions, see the ",(0,i.jsx)(n.a,{href:"/docs/migration/v1.1.0",children:"v1.1.0 Migration Guide"}),"."]})]}),"\n",(0,i.jsx)(n.h3,{id:"understanding-the-impact",children:"Understanding the Impact"}),"\n",(0,i.jsx)(n.p,{children:"The framework normalizes tenant codes to lowercase for case-insensitive matching:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'// Before: Cognito stores uppercase\ncustom:tenant = "MY_TENANT"\n\n// After: getUserContext() returns lowercase\nconst userContext = getUserContext(ctx);\nconsole.log(userContext.tenantCode); // "my_tenant"\n\n// Partition key generation uses lowercase\nconst pk = `PRODUCT#${userContext.tenantCode}`; // "PRODUCT#my_tenant"\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"The problem:"})," If your existing DynamoDB data has partition keys with uppercase tenant codes (e.g., ",(0,i.jsx)(n.code,{children:"PRODUCT#MY_TENANT"}),"), queries using the normalized lowercase tenant code will not find that data."]}),"\n",(0,i.jsx)(n.h3,{id:"strategy-1-update-dynamodb",children:"Migration Strategy 1: Update DynamoDB Data"}),"\n",(0,i.jsx)(n.p,{children:"Migrate existing DynamoDB data to use lowercase tenant codes in partition keys."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/tenant-normalization-migration.service.ts\nimport { Injectable, Logger } from '@nestjs/common';\nimport {\n  DynamoDbService,\n  CommandService,\n  KEY_SEPARATOR,\n  generateId,\n  getTenantCode,\n  IInvoke,\n} from '@mbc-cqrs-serverless/core';\n\n@Injectable()\nexport class TenantNormalizationMigrationService {\n  private readonly logger = new Logger(TenantNormalizationMigrationService.name);\n\n  constructor(\n    private readonly dynamoDbService: DynamoDbService,\n    private readonly commandService: CommandService,\n  ) {}\n\n  /**\n   * Migrate all entities of a type to lowercase tenant codes\n   */\n  async migrateEntityType(\n    tableName: string,\n    entityPrefix: string,\n    invokeContext: IInvoke,\n  ): Promise<{ migrated: number; errors: string[] }> {\n    let migrated = 0;\n    const errors: string[] = [];\n\n    // Scan for items with uppercase tenant codes\n    const items = await this.scanForUppercaseTenants(tableName, entityPrefix);\n\n    for (const item of items) {\n      try {\n        const oldTenantCode = getTenantCode(item.pk);\n        const newTenantCode = oldTenantCode?.toLowerCase();\n\n        if (!newTenantCode || oldTenantCode === newTenantCode) {\n          continue; // Already lowercase or no tenant code\n        }\n\n        // Create new record with lowercase tenant code\n        const newPk = `${entityPrefix}${KEY_SEPARATOR}${newTenantCode}`;\n        const newId = generateId(newPk, item.sk);\n\n        await this.commandService.publishSync({\n          pk: newPk,\n          sk: item.sk,\n          id: newId,\n          tenantCode: newTenantCode,\n          code: item.code,\n          name: item.name,\n          type: item.type,\n          version: 0, // New entity\n          attributes: {\n            ...item.attributes,\n            _migratedFrom: item.id,\n            _migrationReason: 'tenant_code_normalization',\n            _migratedAt: new Date().toISOString(),\n          },\n        }, { invokeContext });\n\n        // Mark old record as migrated (soft delete)\n        await this.commandService.publishPartialUpdateSync({\n          pk: item.pk,\n          sk: item.sk,\n          version: item.version,\n          isDeleted: true,\n          attributes: {\n            ...item.attributes,\n            _migratedTo: newId,\n          },\n        }, { invokeContext });\n\n        migrated++;\n        this.logger.log(`Migrated ${item.id} to ${newId}`);\n      } catch (error) {\n        errors.push(`Failed to migrate ${item.id}: ${error.message}`);\n        this.logger.error(`Migration error for ${item.id}`, error);\n      }\n    }\n\n    return { migrated, errors };\n  }\n\n  private async scanForUppercaseTenants(\n    tableName: string,\n    entityPrefix: string,\n  ): Promise<any[]> {\n    // Implement scanning logic to find items with uppercase tenant codes\n    // Filter for PKs that start with entityPrefix and contain uppercase letters\n    return [];\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"strategy-2-update-cognito",children:"Migration Strategy 2: Update Cognito User Attributes"}),"\n",(0,i.jsx)(n.p,{children:"Update Cognito user attributes to use lowercase tenant codes. This approach avoids data migration but requires Cognito admin access."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/cognito-tenant-migration.service.ts\nimport { Injectable, Logger } from '@nestjs/common';\nimport {\n  CognitoIdentityProviderClient,\n  ListUsersCommand,\n  AdminUpdateUserAttributesCommand,\n} from '@aws-sdk/client-cognito-identity-provider';\n\n@Injectable()\nexport class CognitoTenantMigrationService {\n  private readonly logger = new Logger(CognitoTenantMigrationService.name);\n  private readonly cognitoClient: CognitoIdentityProviderClient;\n\n  constructor() {\n    this.cognitoClient = new CognitoIdentityProviderClient({});\n  }\n\n  /**\n   * Migrate all users' custom:tenant to lowercase\n   */\n  async migrateAllUsers(userPoolId: string): Promise<{\n    migrated: number;\n    errors: string[];\n  }> {\n    let migrated = 0;\n    const errors: string[] = [];\n    let paginationToken: string | undefined;\n\n    do {\n      const listResponse = await this.cognitoClient.send(\n        new ListUsersCommand({\n          UserPoolId: userPoolId,\n          PaginationToken: paginationToken,\n        }),\n      );\n\n      for (const user of listResponse.Users ?? []) {\n        try {\n          const tenantAttr = user.Attributes?.find(\n            (a) => a.Name === 'custom:tenant',\n          );\n          const rolesAttr = user.Attributes?.find(\n            (a) => a.Name === 'custom:roles',\n          );\n\n          if (!tenantAttr?.Value) continue;\n\n          const oldTenant = tenantAttr.Value;\n          const newTenant = oldTenant.toLowerCase();\n\n          if (oldTenant === newTenant) continue; // Already lowercase\n\n          // Update tenant attribute\n          const attributes = [\n            { Name: 'custom:tenant', Value: newTenant },\n          ];\n\n          // Update roles if they contain tenant references\n          if (rolesAttr?.Value) {\n            const roles = JSON.parse(rolesAttr.Value);\n            const updatedRoles = roles.map((r: any) => ({\n              ...r,\n              tenant: (r.tenant || '').toLowerCase(),\n            }));\n            attributes.push({\n              Name: 'custom:roles',\n              Value: JSON.stringify(updatedRoles),\n            });\n          }\n\n          await this.cognitoClient.send(\n            new AdminUpdateUserAttributesCommand({\n              UserPoolId: userPoolId,\n              Username: user.Username,\n              UserAttributes: attributes,\n            }),\n          );\n\n          migrated++;\n          this.logger.log(`Migrated user ${user.Username}`);\n        } catch (error) {\n          errors.push(`Failed to migrate ${user.Username}: ${error.message}`);\n        }\n      }\n\n      paginationToken = listResponse.PaginationToken;\n    } while (paginationToken);\n\n    return { migrated, errors };\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"strategy-3-dual-read",children:"Migration Strategy 3: Dual-Read Approach"}),"\n",(0,i.jsx)(n.p,{children:"For a gradual migration, implement a dual-read approach that tries both lowercase and uppercase tenant codes."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// services/tenant-compatible-data.service.ts\nimport { Injectable } from '@nestjs/common';\nimport {\n  DataService,\n  KEY_SEPARATOR,\n  getTenantCode,\n} from '@mbc-cqrs-serverless/core';\n\n@Injectable()\nexport class TenantCompatibleDataService {\n  constructor(private readonly dataService: DataService) {}\n\n  /**\n   * Get item with fallback to uppercase tenant code\n   */\n  async getItemWithFallback(\n    entityPrefix: string,\n    tenantCode: string,\n    sk: string,\n  ): Promise<any | null> {\n    // Try lowercase first (new format)\n    const lowercasePk = `${entityPrefix}${KEY_SEPARATOR}${tenantCode.toLowerCase()}`;\n    let item = await this.dataService.getItem({ pk: lowercasePk, sk });\n\n    if (item) {\n      return item;\n    }\n\n    // Fallback to uppercase (legacy format)\n    const uppercasePk = `${entityPrefix}${KEY_SEPARATOR}${tenantCode.toUpperCase()}`;\n    item = await this.dataService.getItem({ pk: uppercasePk, sk });\n\n    if (item) {\n      // Log for tracking migration progress\n      console.warn(\n        `Found legacy uppercase data: ${uppercasePk}#${sk}. Consider migrating.`,\n      );\n    }\n\n    return item;\n  }\n\n  /**\n   * List items with fallback to uppercase tenant code\n   */\n  async listItemsWithFallback(\n    entityPrefix: string,\n    tenantCode: string,\n  ): Promise<any[]> {\n    const lowercasePk = `${entityPrefix}${KEY_SEPARATOR}${tenantCode.toLowerCase()}`;\n    const uppercasePk = `${entityPrefix}${KEY_SEPARATOR}${tenantCode.toUpperCase()}`;\n\n    // Query both partitions\n    const [lowercaseItems, uppercaseItems] = await Promise.all([\n      this.dataService.listItemsByPk(lowercasePk),\n      this.dataService.listItemsByPk(uppercasePk),\n    ]);\n\n    // Merge results, preferring lowercase (newer) data\n    const itemMap = new Map<string, any>();\n\n    for (const item of uppercaseItems.items) {\n      itemMap.set(item.sk, item);\n    }\n    for (const item of lowercaseItems.items) {\n      itemMap.set(item.sk, item); // Overwrites uppercase if exists\n    }\n\n    return Array.from(itemMap.values());\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"migration-checklist",children:"Migration Checklist"}),"\n",(0,i.jsx)(n.p,{children:"Follow this checklist when migrating to lowercase tenant codes:"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,i.jsx)(n.strong,{children:"Backup all data"})," before migration"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,i.jsx)(n.strong,{children:"Identify affected tables"})," - scan for uppercase tenant codes in PKs"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,i.jsx)(n.strong,{children:"Choose migration strategy:"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Strategy 1: Update DynamoDB data (recommended for clean migration)"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Strategy 2: Update Cognito attributes (if data is already lowercase)"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Strategy 3: Dual-read (for gradual migration with minimal downtime)"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,i.jsx)(n.strong,{children:"Test migration"})," in a non-production environment"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,i.jsx)(n.strong,{children:"Run migration"})," during low-traffic period"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,i.jsx)(n.strong,{children:"Verify data access"})," after migration"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,i.jsx)(n.strong,{children:"Update RDS data"})," if using RDS sync (tenantCode column)"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,i.jsx)(n.strong,{children:"Remove legacy data"})," after confirming successful migration"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"rds-migration",children:"RDS Migration"}),"\n",(0,i.jsxs)(n.p,{children:["If you're using RDS sync, you also need to update the ",(0,i.jsx)(n.code,{children:"tenantCode"})," column:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"-- Update tenantCode to lowercase in RDS\nUPDATE your_table\nSET tenant_code = LOWER(tenant_code)\nWHERE tenant_code != LOWER(tenant_code);\n"})}),"\n",(0,i.jsx)(n.h3,{id:"verification-script",children:"Verification Script"}),"\n",(0,i.jsx)(n.p,{children:"After migration, verify that all data is accessible:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// scripts/verify-tenant-migration.ts\nasync function verifyMigration(\n  dataService: DataService,\n  entityPrefix: string,\n  tenantCode: string,\n): Promise<{ success: boolean; issues: string[] }> {\n  const issues: string[] = [];\n\n  // Check lowercase data exists\n  const pk = `${entityPrefix}#${tenantCode.toLowerCase()}`;\n  const items = await dataService.listItemsByPk(pk);\n\n  if (items.items.length === 0) {\n    issues.push(`No items found for ${pk}`);\n  }\n\n  // Check no uppercase data remains\n  const uppercasePk = `${entityPrefix}#${tenantCode.toUpperCase()}`;\n  const legacyItems = await dataService.listItemsByPk(uppercasePk);\n\n  if (legacyItems.items.length > 0) {\n    issues.push(\n      `Found ${legacyItems.items.length} legacy items in ${uppercasePk}`,\n    );\n  }\n\n  return {\n    success: issues.length === 0,\n    issues,\n  };\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"cross-tenant-data-migration",children:"Cross-Tenant Data Migration"}),"\n",(0,i.jsx)(n.h3,{id:"pattern-1-copy-data-between-tenants",children:"Pattern 1: Copy Data Between Tenants"}),"\n",(0,i.jsx)(n.p,{children:"Copy data from one tenant to another using the CommandService. This preserves the event sourcing history in the target tenant."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/tenant-migration.service.ts\nimport { Injectable, Logger } from '@nestjs/common';\nimport {\n  CommandService,\n  DataService,\n  KEY_SEPARATOR,\n  generateId,\n  IInvoke,\n} from '@mbc-cqrs-serverless/core';\n\n@Injectable()\nexport class TenantMigrationService {\n  private readonly logger = new Logger(TenantMigrationService.name);\n\n  constructor(\n    private readonly commandService: CommandService,\n    private readonly dataService: DataService,\n  ) {}\n\n  /**\n   * Copy all entities of a type from source to target tenant\n   */\n  async copyEntities(\n    entityType: string,\n    sourceTenantCode: string,\n    targetTenantCode: string,\n    invokeContext: IInvoke,\n  ): Promise<{ copied: number; errors: string[] }> {\n    const sourcePk = `${entityType}${KEY_SEPARATOR}${sourceTenantCode}`;\n    const sourceData = await this.dataService.listItemsByPk(sourcePk);\n\n    let copied = 0;\n    const errors: string[] = [];\n\n    for (const item of sourceData.items) {\n      try {\n        // Create new keys for target tenant\n        const targetPk = `${entityType}${KEY_SEPARATOR}${targetTenantCode}`;\n        const targetId = generateId(targetPk, item.sk);\n\n        await this.commandService.publishSync({\n          pk: targetPk,\n          sk: item.sk,\n          id: targetId,\n          tenantCode: targetTenantCode,\n          code: item.code,\n          name: item.name,\n          type: item.type,\n          attributes: item.attributes,\n          // Track migration source\n          metadata: {\n            migratedFrom: item.id,\n            migratedAt: new Date().toISOString(),\n            sourceTenant: sourceTenantCode,\n          },\n        }, { invokeContext });\n\n        copied++;\n      } catch (error) {\n        errors.push(`Failed to copy ${item.id}: ${error.message}`);\n        this.logger.error(`Migration error for ${item.id}`, error);\n      }\n    }\n\n    this.logger.log(`Copied ${copied} ${entityType} items from ${sourceTenantCode} to ${targetTenantCode}`);\n    return { copied, errors };\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"pattern-2-bulk-migration-with-import-module",children:"Pattern 2: Bulk Migration with Import Module"}),"\n",(0,i.jsx)(n.p,{children:"Use the Import module for large-scale cross-tenant migrations with transformation support."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/bulk-migration.strategy.ts\nimport { Injectable } from '@nestjs/common';\nimport { KEY_SEPARATOR, generateId } from '@mbc-cqrs-serverless/core';\nimport { BaseImportStrategy } from '@mbc-cqrs-serverless/import';\n\nexport interface MigrationInput {\n  sourcePk: string;\n  sourceSk: string;\n  code: string;\n  name: string;\n  attributes: Record<string, any>;\n  targetTenantCode: string;\n}\n\nexport interface MigrationDto {\n  pk: string;\n  sk: string;\n  id: string;\n  code: string;\n  name: string;\n  tenantCode: string;\n  type: string;\n  attributes: Record<string, any>;\n}\n\n@Injectable()\nexport class BulkMigrationImportStrategy\n  extends BaseImportStrategy<MigrationInput, MigrationDto>\n{\n  /**\n   * Transform source data to target tenant format\n   */\n  async transform(input: MigrationInput): Promise<MigrationDto> {\n    const { targetTenantCode } = input;\n\n    // Extract entity type from source PK\n    const pkParts = input.sourcePk.split(KEY_SEPARATOR);\n    const entityType = pkParts[0];\n\n    // Build target keys\n    const targetPk = `${entityType}${KEY_SEPARATOR}${targetTenantCode}`;\n    const targetId = generateId(targetPk, input.sourceSk);\n\n    return {\n      pk: targetPk,\n      sk: input.sourceSk,\n      id: targetId,\n      code: input.code,\n      name: input.name,\n      tenantCode: targetTenantCode,\n      type: entityType,\n      attributes: {\n        ...input.attributes,\n        // Add migration metadata\n        _migrated: true,\n        _sourceKey: `${input.sourcePk}#${input.sourceSk}`,\n      },\n    };\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"schema-evolution-strategies",children:"Schema Evolution Strategies"}),"\n",(0,i.jsx)(n.h3,{id:"strategy-1-backward-compatible-changes",children:"Strategy 1: Backward Compatible Changes"}),"\n",(0,i.jsx)(n.p,{children:"Add new fields with default values. Existing data continues to work without migration."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Backward compatible attribute evolution\ninterface ProductAttributesV1 {\n  name: string;\n  price: number;\n}\n\ninterface ProductAttributesV2 extends ProductAttributesV1 {\n  category?: string;        // New optional field\n  tags?: string[];          // New optional field\n  description?: string;     // New optional field\n}\n\n// product/product.service.ts\n@Injectable()\nexport class ProductService {\n  /**\n   * Get product with schema version handling\n   */\n  async getProduct(key: DetailKey): Promise<ProductDataEntity> {\n    const product = await this.dataService.getItem(key);\n\n    // Apply defaults for missing fields\n    return {\n      ...product,\n      attributes: {\n        ...product.attributes,\n        category: product.attributes.category ?? 'uncategorized',\n        tags: product.attributes.tags ?? [],\n        description: product.attributes.description ?? '',\n      },\n    };\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"strategy-2-data-transformation-migration",children:"Strategy 2: Data Transformation Migration"}),"\n",(0,i.jsx)(n.p,{children:"Transform existing data to a new schema format using the Import module strategies."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/schema-migration.strategy.ts\nimport { Injectable } from '@nestjs/common';\nimport {\n  CommandService,\n  DataService,\n  DataModel,\n} from '@mbc-cqrs-serverless/core';\nimport {\n  BaseProcessStrategy,\n  ComparisonResult,\n  ComparisonStatus,\n} from '@mbc-cqrs-serverless/import';\n\ninterface OldProductAttributes {\n  productName: string;      // Old field name\n  unitPrice: number;        // Old field name\n  categoryCode: string;     // Renamed field\n}\n\ninterface NewProductAttributes {\n  name: string;             // New field name\n  price: number;            // New field name\n  category: string;         // New field name\n  version: 'v2';            // Schema version marker\n}\n\n@Injectable()\nexport class SchemaTransformationStrategy\n  extends BaseProcessStrategy<DataModel, NewProductAttributes>\n{\n  constructor(\n    private readonly commandService: CommandService,\n    private readonly dataService: DataService,\n  ) {\n    super();\n  }\n\n  getCommandService(): CommandService {\n    return this.commandService;\n  }\n\n  /**\n   * Compare to detect schema version differences\n   */\n  async compare(\n    dto: NewProductAttributes,\n    tenantCode: string,\n  ): Promise<ComparisonResult<DataModel>> {\n    // Check if data needs transformation\n    const existing = await this.dataService.getItem({\n      pk: dto.pk,\n      sk: dto.sk,\n    });\n\n    if (!existing) {\n      return { status: ComparisonStatus.NOT_EXIST };\n    }\n\n    // Check schema version\n    if (existing.attributes?.version !== 'v2') {\n      return { status: ComparisonStatus.CHANGED, existingData: existing };\n    }\n\n    return { status: ComparisonStatus.EQUAL };\n  }\n\n  /**\n   * Map old schema to new schema\n   */\n  async map(\n    status: ComparisonStatus,\n    dto: NewProductAttributes,\n    tenantCode: string,\n    existingData?: DataModel,\n  ) {\n    if (status === ComparisonStatus.CHANGED && existingData) {\n      const oldAttrs = existingData.attributes as OldProductAttributes;\n\n      return {\n        pk: existingData.pk,\n        sk: existingData.sk,\n        version: existingData.version,\n        attributes: {\n          // Transform field names\n          name: oldAttrs.productName,\n          price: oldAttrs.unitPrice,\n          category: oldAttrs.categoryCode,\n          version: 'v2',\n        },\n      };\n    }\n\n    return { ...dto, version: 0 };\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"strategy-3-versioned-attributes-pattern",children:"Strategy 3: Versioned Attributes Pattern"}),"\n",(0,i.jsx)(n.p,{children:"Store schema version in attributes for gradual migration."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// entity/versioned-entity.ts\nexport interface VersionedAttributes {\n  _schemaVersion: number;\n  [key: string]: any;\n}\n\n// migration/attribute-migrator.service.ts\n@Injectable()\nexport class AttributeMigratorService {\n  private readonly migrations: Map<number, (attrs: any) => any> = new Map();\n\n  constructor() {\n    // Register migration functions\n    this.migrations.set(1, this.migrateV1ToV2.bind(this));\n    this.migrations.set(2, this.migrateV2ToV3.bind(this));\n  }\n\n  /**\n   * Apply all necessary migrations to bring attributes to current version\n   */\n  migrate(attributes: VersionedAttributes, currentVersion: number): any {\n    let version = attributes._schemaVersion || 1;\n    let result = { ...attributes };\n\n    while (version < currentVersion) {\n      const migrationFn = this.migrations.get(version);\n      if (migrationFn) {\n        result = migrationFn(result);\n        version++;\n      } else {\n        throw new Error(`No migration found for version ${version}`);\n      }\n    }\n\n    result._schemaVersion = currentVersion;\n    return result;\n  }\n\n  private migrateV1ToV2(attrs: any): any {\n    return {\n      ...attrs,\n      // V1 to V2: Split fullName into firstName and lastName\n      firstName: attrs.fullName?.split(' ')[0] ?? '',\n      lastName: attrs.fullName?.split(' ').slice(1).join(' ') ?? '',\n    };\n  }\n\n  private migrateV2ToV3(attrs: any): any {\n    return {\n      ...attrs,\n      // V2 to V3: Add new required fields with defaults\n      createdAt: attrs.createdAt ?? new Date().toISOString(),\n      status: attrs.status ?? 'active',\n    };\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"using-import-module-for-bulk-operations",children:"Using Import Module for Bulk Operations"}),"\n",(0,i.jsx)(n.h3,{id:"csv-based-bulk-migration",children:"CSV-Based Bulk Migration"}),"\n",(0,i.jsx)(n.p,{children:"Export data to CSV, transform, and re-import using the Import module."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/csv-migration.service.ts\nimport { Injectable, Logger } from '@nestjs/common';\nimport { S3Service, DataService, KEY_SEPARATOR } from '@mbc-cqrs-serverless/core';\nimport { ProcessingMode } from '@mbc-cqrs-serverless/import';\nimport { PutObjectCommand } from '@aws-sdk/client-s3';\n\n@Injectable()\nexport class CsvMigrationService {\n  private readonly logger = new Logger(CsvMigrationService.name);\n\n  constructor(\n    private readonly s3Service: S3Service,\n    private readonly dataService: DataService,\n  ) {}\n\n  /**\n   * Export entities to CSV for migration\n   */\n  async exportToMigrationCsv(\n    entityType: string,\n    tenantCode: string,\n    targetTenantCode: string,\n  ): Promise<{ bucket: string; key: string }> {\n    const pk = `${entityType}${KEY_SEPARATOR}${tenantCode}`;\n    const data = await this.dataService.listItemsByPk(pk);\n\n    // Build CSV with migration columns\n    const headers = ['sourcePk', 'sourceSk', 'code', 'name', 'attributes', 'targetTenantCode'];\n    const rows = data.items.map(item => [\n      item.pk,\n      item.sk,\n      item.code,\n      item.name,\n      JSON.stringify(item.attributes),\n      targetTenantCode,\n    ]);\n\n    const csvContent = [\n      headers.join(','),\n      ...rows.map(row => row.map(this.escapeCsvValue).join(',')),\n    ].join('\\n');\n\n    // Upload to S3\n    const bucket = this.s3Service.privateBucket;\n    const key = `migrations/${Date.now()}/migration-${entityType}-${tenantCode}-to-${targetTenantCode}.csv`;\n\n    await this.s3Service.client.send(new PutObjectCommand({\n      Bucket: bucket,\n      Key: key,\n      Body: csvContent,\n      ContentType: 'text/csv; charset=utf-8',\n    }));\n\n    this.logger.log(`Exported ${data.items.length} items to ${key}`);\n    return { bucket, key };\n  }\n\n  /**\n   * Create migration import job\n   */\n  async startMigrationImport(\n    bucket: string,\n    key: string,\n    tenantCode: string,\n  ): Promise<{ jobId: string }> {\n    // Import module handles the migration via configured strategy\n    // The strategy will transform data to target tenant format\n    return {\n      jobId: `migration-${Date.now()}`,\n      // Actual job creation would use ImportModule API\n    };\n  }\n\n  private escapeCsvValue(value: any): string {\n    if (value === null || value === undefined) return '';\n    const str = String(value);\n    if (str.includes(',') || str.includes('\"') || str.includes('\\n')) {\n      return `\"${str.replace(/\"/g, '\"\"')}\"`;\n    }\n    return str;\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"import-process-strategy-for-migration",children:"Import Process Strategy for Migration"}),"\n",(0,i.jsx)(n.p,{children:"Implement a process strategy that handles migration-specific logic."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/migration-process.strategy.ts\nimport { Injectable } from '@nestjs/common';\nimport {\n  CommandService,\n  DataService,\n  DataModel,\n  CommandInputModel,\n  CommandPartialInputModel,\n} from '@mbc-cqrs-serverless/core';\nimport {\n  BaseProcessStrategy,\n  ComparisonResult,\n  ComparisonStatus,\n  IProcessStrategy,\n} from '@mbc-cqrs-serverless/import';\n\ninterface MigrationDto {\n  pk: string;\n  sk: string;\n  id: string;\n  code: string;\n  name: string;\n  tenantCode: string;\n  type: string;\n  attributes: Record<string, any>;\n}\n\n@Injectable()\nexport class MigrationProcessStrategy\n  extends BaseProcessStrategy<DataModel, MigrationDto>\n  implements IProcessStrategy<DataModel, MigrationDto>\n{\n  constructor(\n    private readonly commandService: CommandService,\n    private readonly dataService: DataService,\n  ) {\n    super();\n  }\n\n  getCommandService(): CommandService {\n    return this.commandService;\n  }\n\n  /**\n   * Compare migrated data with existing target data\n   */\n  async compare(\n    dto: MigrationDto,\n    tenantCode: string,\n  ): Promise<ComparisonResult<DataModel>> {\n    try {\n      const existing = await this.dataService.getItem({\n        pk: dto.pk,\n        sk: dto.sk,\n      });\n\n      if (!existing) {\n        return { status: ComparisonStatus.NOT_EXIST };\n      }\n\n      // Check if already migrated\n      if (existing.attributes?._migrated) {\n        return { status: ComparisonStatus.EQUAL };\n      }\n\n      // Data exists but not migrated - update it\n      return { status: ComparisonStatus.CHANGED, existingData: existing };\n    } catch (error) {\n      return { status: ComparisonStatus.NOT_EXIST };\n    }\n  }\n\n  /**\n   * Map migration data to command payload\n   */\n  async map(\n    status: ComparisonStatus,\n    dto: MigrationDto,\n    tenantCode: string,\n    existingData?: DataModel,\n  ): Promise<CommandInputModel | CommandPartialInputModel> {\n    if (status === ComparisonStatus.NOT_EXIST) {\n      // Create new record\n      return {\n        pk: dto.pk,\n        sk: dto.sk,\n        id: dto.id,\n        tenantCode: dto.tenantCode,\n        code: dto.code,\n        name: dto.name,\n        type: dto.type,\n        version: 0,\n        attributes: dto.attributes,\n      };\n    }\n\n    // Update existing record\n    return {\n      pk: dto.pk,\n      sk: dto.sk,\n      version: existingData?.version ?? 0,\n      attributes: {\n        ...existingData?.attributes,\n        ...dto.attributes,\n        _migrated: true,\n        _migratedAt: new Date().toISOString(),\n      },\n    };\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"rollback-procedures",children:"Rollback Procedures"}),"\n",(0,i.jsx)(n.h3,{id:"event-sourcing-based-rollback",children:"Event Sourcing Based Rollback"}),"\n",(0,i.jsx)(n.p,{children:"Leverage the history table to restore previous versions."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/rollback.service.ts\nimport { Injectable, Logger } from '@nestjs/common';\nimport {\n  CommandService,\n  DataService,\n  HistoryService,\n  IInvoke,\n} from '@mbc-cqrs-serverless/core';\n\n@Injectable()\nexport class RollbackService {\n  private readonly logger = new Logger(RollbackService.name);\n\n  constructor(\n    private readonly commandService: CommandService,\n    private readonly dataService: DataService,\n    private readonly historyService: HistoryService,\n  ) {}\n\n  /**\n   * Rollback entity to a specific version\n   */\n  async rollbackToVersion(\n    pk: string,\n    sk: string,\n    targetVersion: number,\n    invokeContext: IInvoke,\n  ): Promise<void> {\n    // Get historical version\n    const historicalData = await this.historyService.getVersion(\n      pk,\n      sk,\n      targetVersion,\n    );\n\n    if (!historicalData) {\n      throw new Error(`Version ${targetVersion} not found for ${pk}#${sk}`);\n    }\n\n    // Get current version for optimistic locking\n    const currentData = await this.dataService.getItem({ pk, sk });\n\n    // Restore to historical state\n    await this.commandService.publishSync({\n      pk,\n      sk,\n      id: currentData.id,\n      tenantCode: currentData.tenantCode,\n      code: historicalData.code,\n      name: historicalData.name,\n      type: historicalData.type,\n      version: currentData.version,\n      attributes: {\n        ...historicalData.attributes,\n        _rolledBackFrom: currentData.version,\n        _rolledBackAt: new Date().toISOString(),\n      },\n    }, { invokeContext });\n\n    this.logger.log(`Rolled back ${pk}#${sk} from v${currentData.version} to v${targetVersion}`);\n  }\n\n  /**\n   * Rollback migration by timestamp\n   */\n  async rollbackMigration(\n    entityType: string,\n    tenantCode: string,\n    migrationTimestamp: string,\n    invokeContext: IInvoke,\n  ): Promise<{ rolledBack: number; errors: string[] }> {\n    const pk = `${entityType}#${tenantCode}`;\n    const data = await this.dataService.listItemsByPk(pk);\n\n    let rolledBack = 0;\n    const errors: string[] = [];\n\n    for (const item of data.items) {\n      // Check if item was part of the migration\n      if (item.attributes?._migratedAt === migrationTimestamp) {\n        try {\n          // Find version before migration\n          const history = await this.historyService.listVersions(\n            item.pk,\n            item.sk,\n          );\n\n          const preVersion = history.find(h =>\n            !h.attributes?._migrated ||\n            new Date(h.updatedAt) < new Date(migrationTimestamp)\n          );\n\n          if (preVersion) {\n            await this.rollbackToVersion(\n              item.pk,\n              item.sk,\n              preVersion.version,\n              invokeContext,\n            );\n            rolledBack++;\n          }\n        } catch (error) {\n          errors.push(`Failed to rollback ${item.id}: ${error.message}`);\n        }\n      }\n    }\n\n    return { rolledBack, errors };\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"soft-delete-pattern-for-safe-rollback",children:"Soft Delete Pattern for Safe Rollback"}),"\n",(0,i.jsx)(n.p,{children:"Use soft delete to enable easy recovery."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/safe-migration.service.ts\n@Injectable()\nexport class SafeMigrationService {\n  /**\n   * Migrate with soft delete for rollback capability\n   */\n  async migrateWithSoftDelete(\n    sourcePk: string,\n    targetPk: string,\n    invokeContext: IInvoke,\n  ): Promise<{ migratedIds: string[]; originalIds: string[] }> {\n    const sourceData = await this.dataService.listItemsByPk(sourcePk);\n\n    const migratedIds: string[] = [];\n    const originalIds: string[] = [];\n\n    for (const item of sourceData.items) {\n      // Create new record in target\n      const targetId = generateId(targetPk, item.sk);\n      await this.commandService.publishSync({\n        pk: targetPk,\n        sk: item.sk,\n        id: targetId,\n        tenantCode: this.extractTenant(targetPk),\n        code: item.code,\n        name: item.name,\n        type: item.type,\n        attributes: {\n          ...item.attributes,\n          _migratedFrom: item.id,\n        },\n      }, { invokeContext });\n      migratedIds.push(targetId);\n\n      // Soft delete original (don't hard delete)\n      await this.commandService.publishPartialUpdateSync({\n        pk: item.pk,\n        sk: item.sk,\n        version: item.version,\n        isDeleted: true,\n        attributes: {\n          ...item.attributes,\n          _migratedTo: targetId,\n          _deletedAt: new Date().toISOString(),\n        },\n      }, { invokeContext });\n      originalIds.push(item.id);\n    }\n\n    return { migratedIds, originalIds };\n  }\n\n  /**\n   * Rollback by restoring soft-deleted records\n   */\n  async rollbackSoftDeleteMigration(\n    originalIds: string[],\n    migratedIds: string[],\n    invokeContext: IInvoke,\n  ): Promise<void> {\n    // Restore original records\n    for (const id of originalIds) {\n      const item = await this.dataService.getItemById(id);\n      if (item?.isDeleted) {\n        await this.commandService.publishPartialUpdateSync({\n          pk: item.pk,\n          sk: item.sk,\n          version: item.version,\n          isDeleted: false,\n          attributes: {\n            ...item.attributes,\n            _migratedTo: undefined,\n            _deletedAt: undefined,\n            _restoredAt: new Date().toISOString(),\n          },\n        }, { invokeContext });\n      }\n    }\n\n    // Hard delete migrated records\n    for (const id of migratedIds) {\n      const item = await this.dataService.getItemById(id);\n      if (item) {\n        await this.commandService.publishPartialUpdateSync({\n          pk: item.pk,\n          sk: item.sk,\n          version: item.version,\n          isDeleted: true,\n        }, { invokeContext });\n      }\n    }\n  }\n\n  private extractTenant(pk: string): string {\n    return pk.split('#')[1] ?? 'unknown';\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"data-validation-during-migration",children:"Data Validation During Migration"}),"\n",(0,i.jsx)(n.h3,{id:"pre-migration-validation",children:"Pre-Migration Validation"}),"\n",(0,i.jsx)(n.p,{children:"Validate data before starting migration."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/validation.service.ts\nimport { Injectable, Logger } from '@nestjs/common';\nimport { DataService, KEY_SEPARATOR } from '@mbc-cqrs-serverless/core';\nimport { validate } from 'class-validator';\nimport { plainToInstance } from 'class-transformer';\n\nexport interface ValidationResult {\n  valid: boolean;\n  totalRecords: number;\n  validRecords: number;\n  invalidRecords: ValidationError[];\n}\n\nexport interface ValidationError {\n  id: string;\n  errors: string[];\n}\n\n@Injectable()\nexport class MigrationValidationService {\n  private readonly logger = new Logger(MigrationValidationService.name);\n\n  constructor(private readonly dataService: DataService) {}\n\n  /**\n   * Validate all records before migration\n   */\n  async validateBeforeMigration<T extends object>(\n    entityType: string,\n    tenantCode: string,\n    dtoClass: new () => T,\n  ): Promise<ValidationResult> {\n    const pk = `${entityType}${KEY_SEPARATOR}${tenantCode}`;\n    const data = await this.dataService.listItemsByPk(pk);\n\n    const invalidRecords: ValidationError[] = [];\n    let validCount = 0;\n\n    for (const item of data.items) {\n      const dto = plainToInstance(dtoClass, item.attributes);\n      const errors = await validate(dto);\n\n      if (errors.length > 0) {\n        invalidRecords.push({\n          id: item.id,\n          errors: errors.map(e => Object.values(e.constraints ?? {}).join(', ')),\n        });\n      } else {\n        validCount++;\n      }\n    }\n\n    const result: ValidationResult = {\n      valid: invalidRecords.length === 0,\n      totalRecords: data.items.length,\n      validRecords: validCount,\n      invalidRecords,\n    };\n\n    this.logger.log(`Validation result: ${validCount}/${data.items.length} valid`);\n    return result;\n  }\n\n  /**\n   * Validate referential integrity\n   */\n  async validateReferences(\n    entityType: string,\n    tenantCode: string,\n    referenceField: string,\n    referenceEntityType: string,\n  ): Promise<ValidationError[]> {\n    const pk = `${entityType}${KEY_SEPARATOR}${tenantCode}`;\n    const data = await this.dataService.listItemsByPk(pk);\n\n    const refPk = `${referenceEntityType}${KEY_SEPARATOR}${tenantCode}`;\n    const refData = await this.dataService.listItemsByPk(refPk);\n    const validRefs = new Set(refData.items.map(r => r.id));\n\n    const errors: ValidationError[] = [];\n\n    for (const item of data.items) {\n      const refValue = item.attributes?.[referenceField];\n      if (refValue && !validRefs.has(refValue)) {\n        errors.push({\n          id: item.id,\n          errors: [`Invalid reference: ${referenceField}=${refValue} not found`],\n        });\n      }\n    }\n\n    return errors;\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"post-migration-verification",children:"Post-Migration Verification"}),"\n",(0,i.jsx)(n.p,{children:"Verify data integrity after migration."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// migration/verification.service.ts\n@Injectable()\nexport class MigrationVerificationService {\n  /**\n   * Verify migration completed successfully\n   */\n  async verifyMigration(\n    sourcePk: string,\n    targetPk: string,\n  ): Promise<{\n    success: boolean;\n    sourceCount: number;\n    targetCount: number;\n    missingItems: string[];\n    extraItems: string[];\n  }> {\n    const sourceData = await this.dataService.listItemsByPk(sourcePk);\n    const targetData = await this.dataService.listItemsByPk(targetPk);\n\n    const sourceIds = new Set(sourceData.items.map(i => i.sk));\n    const targetIds = new Set(targetData.items.map(i => i.sk));\n\n    const missingItems: string[] = [];\n    const extraItems: string[] = [];\n\n    // Find items in source but not in target\n    for (const sk of sourceIds) {\n      if (!targetIds.has(sk)) {\n        missingItems.push(sk);\n      }\n    }\n\n    // Find items in target but not in source\n    for (const sk of targetIds) {\n      if (!sourceIds.has(sk)) {\n        extraItems.push(sk);\n      }\n    }\n\n    return {\n      success: missingItems.length === 0,\n      sourceCount: sourceData.items.length,\n      targetCount: targetData.items.length,\n      missingItems,\n      extraItems,\n    };\n  }\n\n  /**\n   * Compare data content between source and target\n   */\n  async compareContent(\n    sourcePk: string,\n    targetPk: string,\n    compareFields: string[],\n  ): Promise<{ differences: Array<{ sk: string; field: string; source: any; target: any }> }> {\n    const sourceData = await this.dataService.listItemsByPk(sourcePk);\n    const targetData = await this.dataService.listItemsByPk(targetPk);\n\n    const targetMap = new Map(targetData.items.map(i => [i.sk, i]));\n    const differences: Array<{ sk: string; field: string; source: any; target: any }> = [];\n\n    for (const sourceItem of sourceData.items) {\n      const targetItem = targetMap.get(sourceItem.sk);\n      if (!targetItem) continue;\n\n      for (const field of compareFields) {\n        const sourceValue = sourceItem.attributes?.[field];\n        const targetValue = targetItem.attributes?.[field];\n\n        if (JSON.stringify(sourceValue) !== JSON.stringify(targetValue)) {\n          differences.push({\n            sk: sourceItem.sk,\n            field,\n            source: sourceValue,\n            target: targetValue,\n          });\n        }\n      }\n    }\n\n    return { differences };\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsx)(n.h3,{id:"1-always-use-transactions-when-possible",children:"1. Always Use Transactions When Possible"}),"\n",(0,i.jsx)(n.p,{children:"DynamoDB transactions ensure atomic operations:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Use batch writes for related items\nawait this.dataService.transactWrite([\n  { put: sourceUpdateItem },\n  { put: targetCreateItem },\n]);\n"})}),"\n",(0,i.jsx)(n.h3,{id:"2-track-migration-metadata",children:"2. Track Migration Metadata"}),"\n",(0,i.jsx)(n.p,{children:"Store migration information for auditing:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"attributes: {\n  ...originalAttributes,\n  _migrationId: migrationJobId,\n  _migratedAt: new Date().toISOString(),\n  _migratedBy: userContext.userId,\n  _sourceVersion: sourceItem.version,\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"3-implement-idempotent-migrations",children:"3. Implement Idempotent Migrations"}),"\n",(0,i.jsx)(n.p,{children:"Make migrations safe to re-run:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Check if already migrated before processing\nif (item.attributes?._migrationId === currentMigrationId) {\n  this.logger.log(`Skipping already migrated item: ${item.id}`);\n  continue;\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"4-use-batch-processing-for-large-datasets",children:"4. Use Batch Processing for Large Datasets"}),"\n",(0,i.jsx)(n.p,{children:"Process in batches to avoid timeouts and memory issues:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"const BATCH_SIZE = 25; // DynamoDB limit\n\nfor (let i = 0; i < items.length; i += BATCH_SIZE) {\n  const batch = items.slice(i, i + BATCH_SIZE);\n  await Promise.all(batch.map(item => this.migrateItem(item)));\n  this.logger.log(`Processed ${Math.min(i + BATCH_SIZE, items.length)}/${items.length}`);\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"5-create-migration-checkpoints",children:"5. Create Migration Checkpoints"}),"\n",(0,i.jsx)(n.p,{children:"Save progress for resumable migrations:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"interface MigrationCheckpoint {\n  migrationId: string;\n  lastProcessedSk: string;\n  processedCount: number;\n  status: 'in_progress' | 'completed' | 'failed';\n  updatedAt: string;\n}\n\n// Resume from checkpoint if migration was interrupted\nconst checkpoint = await this.getCheckpoint(migrationId);\nconst startFrom = checkpoint?.lastProcessedSk ?? '';\n"})}),"\n",(0,i.jsx)(n.h2,{id:"related-documentation",children:"Related Documentation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"./import-export-patterns",children:"Import/Export Patterns"})," - Bulk data operations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"./multi-tenant-patterns",children:"Multi-Tenant Patterns"})," - Tenant isolation strategies"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"./data-sync-handler-examples",children:"Data Sync Handler Examples"})," - Sync handler patterns"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"./version-conflict-guide",children:"Version Conflict Guide"})," - Handling version conflicts"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var r=t(6540);const i={},a=r.createContext(i);function s(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);