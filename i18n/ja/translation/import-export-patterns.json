{
  "Learn patterns for importing and exporting data in CSV and Excel formats with batch processing and validation.": "バッチ処理とバリデーションを使用したCSVおよびExcel形式でのデータインポート・エクスポートパターンを学びます。",
  "Import/Export Patterns": "インポート/エクスポートパターン",
  "This guide covers patterns for handling data import and export operations, including CSV processing, Excel file handling, and batch data operations with Step Functions.": "このガイドでは、CSVの処理、Excelファイルの処理、Step Functionsを使用したバッチデータ操作など、データのインポートおよびエクスポート操作のパターンについて説明します。",
  "When to Use This Guide": "このガイドを使用するタイミング",
  "Use this guide when you need to:": "以下の場合にこのガイドを使用してください：",
  "Import bulk data from CSV or Excel files": "CSVまたはExcelファイルから一括データをインポートする",
  "Export data to various formats": "様々な形式にデータをエクスポートする",
  "Process large datasets with Step Functions": "Step Functionsで大規模なデータセットを処理する",
  "Implement file upload with S3 presigned URLs": "S3署名付きURLでファイルアップロードを実装する",
  "Transform data between external and internal formats": "外部形式と内部形式の間でデータを変換する",
  "Import Architecture Overview": "インポートアーキテクチャの概要",
  "File Upload Pattern": "ファイルアップロードパターン",
  "Storage Service": "ストレージサービス",
  "Generate presigned URLs for secure file uploads:": "安全なファイルアップロードのための署名付きURLを生成します：",
  "Generate upload URL for file import": "Generate upload URL for file import (ファイルインポート用のアップロードURLを生成)",
  "1 hour": "1 hour (1時間)",
  "Generate download URL for file export": "Generate download URL for file export (ファイルエクスポート用のダウンロードURLを生成)",
  "Storage Controller": "ストレージコントローラー",
  "Get presigned URL for upload": "Get presigned URL for upload (アップロード用の署名付きURLを取得)",
  "Get presigned URL for download": "Get presigned URL for download (ダウンロード用の署名付きURLを取得)",
  "CSV Import Pattern": "CSVインポートパターン",
  "CSV Import Controller": "CSVインポートコントローラー",
  "Import type identifier": "Import type identifier (インポートタイプ識別子)",
  "Start CSV import via Step Functions": "Start CSV import via Step Functions (Step FunctionsでCSVインポートを開始)",
  "CSV Parser Service": "CSVパーサーサービス",
  "Parse CSV file from S3": "Parse CSV file from S3 (S3からCSVファイルを解析)",
  "Validate parsed rows": "Validate parsed rows (解析された行をバリデート)",
  "Import Event Handler": "インポートイベントハンドラー",
  "Process CSV import event": "Process CSV import event (CSVインポートイベントを処理)",
  "Parse CSV": "Parse CSV (CSVを解析)",
  "Validate": "Validate (バリデート)",
  "Filter valid rows": "Filter valid rows (有効な行をフィルタ)",
  "Process in batches": "Process in batches (バッチで処理)",
  "Excel Import Pattern": "Excelインポートパターン",
  "Excel Helper Functions": "Excelヘルパー関数",
  "Get cell value handling formulas and rich text": "Get cell value handling formulas and rich text (数式やリッチテキストを処理してセル値を取得)",
  "Handle formula result": "Handle formula result (数式の結果を処理)",
  "Handle rich text": "Handle rich text (リッチテキストを処理)",
  "Get numeric cell value": "Get numeric cell value (数値のセル値を取得)",
  "Get date cell value": "Get date cell value (日付のセル値を取得)",
  "Find header row by matching column headers": "Find header row by matching column headers (列ヘッダーをマッチングしてヘッダー行を検索)",
  "Excel Import Service": "Excelインポートサービス",
  "Load workbook from S3": "Load workbook from S3 (S3からワークブックを読み込む)",
  "For .xls files, use different parser": "For .xls files, use different parser (.xlsファイルには別のパーサーを使用)",
  "Process worksheet with row processor": "Process worksheet with row processor (行プロセッサでワークシートを処理)",
  "Find or use specified header row": "Find or use specified header row (ヘッダー行を検索または指定されたものを使用)",
  "Skip empty rows": "Skip empty rows (空行をスキップ)",
  "Import Strategy Pattern": "インポートストラテジーパターン",
  "Base interface for import strategies": "Base interface for import strategies (インポート戦略の基本インターフェース)",
  "Transform raw input to command DTO": "Transform raw input to command DTO (生の入力をコマンドDTOに変換)",
  "Validate transformed DTO": "Validate transformed DTO (変換後のDTOをバリデート)",
  "Base import strategy with common functionality": "Base import strategy with common functionality (共通機能を持つ基本インポート戦略)",
  "Transform raw input to command DTO (default: return as-is)": "Transform raw input to command DTO (default: return as-is) (生の入力をコマンドDTOに変換、デフォルト：そのまま返す)",
  "Validate transformed DTO using class-validator": "Validate transformed DTO using class-validator (class-validatorを使用して変換後のDTOをバリデート)",
  "Uses class-validator for validation": "Uses class-validator for validation (class-validatorでバリデーションを実行)",
  "Flatten validation errors to a simple format": "Flatten validation errors to a simple format (バリデーションエラーをシンプルな形式にフラット化)",
  "The input type, must be an object": "The input type, must be an object (入力型、オブジェクトである必要があります)",
  "The output DTO type, must be an object": "The output DTO type, must be an object (出力DTO型、オブジェクトである必要があります)",
  "Concrete Import Strategy": "具象インポートストラテジー",
  "Transform import data to command DTO": "Transform import data to command DTO (インポートデータをコマンドDTOに変換)",
  "Validate import input": "Validate import input (インポート入力をバリデート)",
  "Export Pattern": "エクスポートパターン",
  "Export Service": "エクスポートサービス",
  "Export data to CSV and upload to S3": "Export data to CSV and upload to S3 (データをCSVにエクスポートしてS3にアップロード)",
  "Build CSV content": "Build CSV content (CSVコンテンツを構築)",
  "Upload to S3": "Upload to S3 (S3にアップロード)",
  "Export data to Excel and upload to S3": "Export data to Excel and upload to S3 (データをExcelにエクスポートしてS3にアップロード)",
  "Set columns": "Set columns (列を設定)",
  "Style header row": "Style header row (ヘッダー行にスタイルを適用)",
  "Add data rows": "Add data rows (データ行を追加)",
  "Generate buffer": "Generate buffer (バッファを生成)",
  "Step Function Integration": "Step Functions統合",
  "Import Orchestration": "インポートオーケストレーション",
  "Import workflow with Step Functions": "Import workflow with Step Functions (Step Functionsによるインポートワークフロー)",
  "Best Practices": "ベストプラクティス",
  "1. Batch Processing": "1. バッチ処理",
  "Always process large files in batches:": "大きなファイルは常にバッチで処理します：",
  "2. Error Handling": "2. エラーハンドリング",
  "Collect and report errors without stopping processing:": "処理を停止せずにエラーを収集し報告します：",
  "Continue processing": "Continue processing (処理を継続)",
  "3. Validation Before Processing": "3. 処理前のバリデーション",
  "Validate all data before starting import:": "インポートを開始する前にすべてのデータをバリデーションします：",
  "First pass: validate": "First pass: validate (最初のパス：バリデート)",
  "Second pass: process": "Second pass: process (2番目のパス：処理)",
  "4. Progress Reporting": "4. 進捗報告",
  "Report progress for long-running imports:": "長時間実行されるインポートの進捗を報告します：",
  "Report progress every 100 rows": "Report progress every 100 rows (100行ごとに進捗を報告)",
  "ImportModule API Reference": "ImportModule APIリファレンス",
  "The `@mbc-cqrs-serverless/import` package provides a comprehensive framework for managing data import tasks.": "`@mbc-cqrs-serverless/import`パッケージは、データインポートタスクを管理するための包括的なフレームワークを提供します。",
  "Installation": "インストール",
  "ProcessingMode Enum": "ProcessingMode列挙型",
  "The `ProcessingMode` enum defines how import jobs are executed:": "`ProcessingMode`列挙型は、インポートジョブの実行方法を定義します：",
  "Direct processing without Step Functions": "Direct processing without Step Functions (Step Functionsを使用しない直接処理)",
  "Processing orchestrated by Step Functions": "Processing orchestrated by Step Functions (Step Functionsによるオーケストレーション処理)",
  "Mode": "モード",
  "Description": "説明",
  "Use Case": "ユースケース",
  "Import is processed directly without Step Functions orchestration": "Step Functionsオーケストレーションを使用せずにインポートを直接処理",
  "Small imports, simple data": "小規模インポート、シンプルなデータ",
  "Import is orchestrated by Step Functions for reliability": "信頼性のためにStep Functionsでインポートをオーケストレーション",
  "Large imports, complex workflows, ZIP imports": "大規模インポート、複雑なワークフロー、ZIPインポート",
  "CreateCsvImportDto": "CreateCsvImportDto",
  "The `CreateCsvImportDto` is used to start a CSV import job:": "`CreateCsvImportDto`はCSVインポートジョブを開始するために使用されます：",
  "Optional source identifier": "Optional source identifier (オプションのソース識別子)",
  "How the import should be processed": "How the import should be processed (インポートの処理方法)",
  "S3 bucket containing the CSV file": "S3 bucket containing the CSV file (CSVファイルを含むS3バケット)",
  "S3 key (path) to the CSV file": "S3 key (path) to the CSV file (CSVファイルへのS3キー（パス）)",
  "Target table name for import profile matching": "Target table name for import profile matching (インポートプロファイルマッチング用のターゲットテーブル名)",
  "Tenant code for multi-tenancy": "Tenant code for multi-tenancy (マルチテナンシー用のテナントコード)",
  "Property": "プロパティ",
  "Type": "型",
  "Required": "必須",
  "No": "いいえ",
  "Optional identifier for the import source": "インポートソースのオプション識別子",
  "Yes": "はい",
  "DIRECT or STEP_FUNCTION mode": "DIRECTまたはSTEP_FUNCTIONモード",
  "Target table name, used to match import profile": "ターゲットテーブル名、インポートプロファイルのマッチングに使用",
  "CreateZipImportDto": "CreateZipImportDto",
  "The `CreateZipImportDto` is used to start a ZIP import job that contains multiple CSV files:": "`CreateZipImportDto`は複数のCSVファイルを含むZIPインポートジョブを開始するために使用されます：",
  "S3 bucket containing the ZIP file": "S3 bucket containing the ZIP file (ZIPファイルを含むS3バケット)",
  "S3 key (path) to the ZIP file": "S3 key (path) to the ZIP file (ZIPファイルへのS3キー（パス）)",
  "High priority: sortedFileKeys": "High priority: sortedFileKeys (高優先度: sortedFileKeys)",
  "If not provided, it will use the default sorting logic": "If not provided, it will use the default sorting logic (指定されない場合、デフォルトのソートロジックを使用)",
  "Optional ordered list of file keys to process": "Optional ordered list of file keys to process (処理するファイルキーのオプションの順序付きリスト)",
  "High priority: tableName": "High priority: tableName (高優先度: tableName)",
  "If not provided, it will be extracted from the filename": "If not provided, it will be extracted from the filename (指定されない場合、ファイル名から抽出)",
  "Optional table name override": "Optional table name override (オプションのテーブル名オーバーライド)",
  "Ordered list of file keys to process. If not provided, default sorting is used": "処理するファイルキーの順序付きリスト。指定されない場合、デフォルトのソートが使用される",
  "Table name override. If not provided, extracted from filename (format: yyyymmddhhMMss-\\{tableName\\}.csv)": "テーブル名のオーバーライド。指定されない場合、ファイル名から抽出（形式: yyyymmddhhMMss-\\{tableName\\}.csv）",
  "Core Concepts": "コアコンセプト",
  "ComparisonStatus Enum": "ComparisonStatus列挙型",
  "The `ComparisonStatus` enum defines the result of comparing imported data with existing data:": "`ComparisonStatus`列挙型は、インポートデータと既存データの比較結果を定義します：",
  "Data exists and is identical - no action needed": "Data exists and is identical - no action needed (データが存在し同一 - アクション不要)",
  "Data does not exist - create new record": "Data does not exist - create new record (データが存在しない - 新規レコード作成)",
  "Data exists but differs - update existing record": "Data exists but differs - update existing record (データは存在するが異なる - 既存レコード更新)",
  "Value": "値",
  "Imported data matches existing data": "インポートデータが既存データと一致",
  "Skip (no operation)": "スキップ（操作なし）",
  "No existing data found": "既存データが見つからない",
  "Create new record": "新規レコード作成",
  "Existing data differs from imported data": "既存データがインポートデータと異なる",
  "Update existing record": "既存レコード更新",
  "ComparisonResult Interface": "ComparisonResultインターフェース",
  "The `ComparisonResult<TEntity>` interface wraps the comparison status with optional existing data. The generic type `TEntity` must extend `DataModel`:": "`ComparisonResult<TEntity>`インターフェースは、比較ステータスとオプションの既存データをラップします。ジェネリック型`TEntity`は`DataModel`を拡張する必要があります：",
  "The result of the comparison": "The result of the comparison (比較結果)",
  "If the status is 'CHANGED', this property holds the existing entity data": "If the status is 'CHANGED', this property holds the existing entity data (ステータスが'CHANGED'の場合、このプロパティは既存エンティティデータを保持)",
  "retrieved from the database. It is undefined otherwise.": "retrieved from the database. It is undefined otherwise. (データベースから取得。それ以外の場合はundefined)",
  "The comparison result status": "比較結果ステータス",
  "The existing entity data, present when status is CHANGED": "既存エンティティデータ、ステータスがCHANGEDの場合に存在",
  "IProcessStrategy Interface": "IProcessStrategyインターフェース",
  "The `IProcessStrategy` interface defines the contract for processing validated import data. Note that the generic type `TEntity` must extend `DataModel`:": "`IProcessStrategy`インターフェースは、バリデーション済みインポートデータを処理するための契約を定義します。ジェネリック型`TEntity`は`DataModel`を拡張する必要があることに注意してください：",
  "Get the command service for publishing commands": "Get the command service for publishing commands (コマンド発行用のコマンドサービスを取得)",
  "Compare the validated DTO with existing data": "Compare the validated DTO with existing data (バリデーション済みDTOを既存データと比較)",
  "Map the DTO to a command payload based on comparison status": "Map the DTO to a command payload based on comparison status (比較ステータスに基づいてDTOをコマンドペイロードにマッピング)",
  "Note: status excludes EQUAL since no mapping is needed for identical data": "Note: status excludes EQUAL since no mapping is needed for identical data (注意: 同一データではマッピング不要のためstatusはEQUALを除外)",
  "CommandInputModel for create, CommandPartialInputModel for update": "CommandInputModel for create, CommandPartialInputModel for update (作成用CommandInputModel、更新用CommandPartialInputModel)",
  "BaseProcessStrategy Abstract Class": "BaseProcessStrategy抽象クラス",
  "The `BaseProcessStrategy` abstract class provides a base implementation that subclasses must extend. The generic type `TEntity` must extend `DataModel`:": "`BaseProcessStrategy`抽象クラスは、サブクラスが拡張する必要がある基本実装を提供します。ジェネリック型`TEntity`は`DataModel`を拡張する必要があります：",
  "Abstract method - must be implemented to return the command service": "Abstract method - must be implemented to return the command service (抽象メソッド - コマンドサービスを返すために実装が必要)",
  "Abstract method - must be implemented to compare data": "Abstract method - must be implemented to compare data (抽象メソッド - データ比較のために実装が必要)",
  "Abstract method - must be implemented to map data to command payload": "Abstract method - must be implemented to map data to command payload (抽象メソッド - データをコマンドペイロードにマッピングするために実装が必要)",
  "Note": "注意",
  "All three methods (`compare()`, `map()`, `getCommandService()`) in `BaseProcessStrategy` are abstract and must be implemented by subclasses.": "`BaseProcessStrategy`の3つのメソッド（`compare()`、`map()`、`getCommandService()`）はすべて抽象メソッドであり、サブクラスで実装する必要があります。",
  "Return CommandInputModel for creating new records": "Return CommandInputModel for creating new records (新規レコード作成用にCommandInputModelを返す)",
  "status === ComparisonStatus.CHANGED": "status === ComparisonStatus.CHANGED (ステータスがCHANGEDの場合)",
  "Return CommandPartialInputModel for updating existing records": "Return CommandPartialInputModel for updating existing records (既存レコード更新用にCommandPartialInputModelを返す)",
  "The module operates on a two-phase architecture:": "このモジュールは2フェーズアーキテクチャで動作します：",
  "**Import Phase** (`IImportStrategy`): Transform raw data (from JSON or CSV) into a standardized DTO and validate it.": "**インポートフェーズ**（`IImportStrategy`）：生データ（JSONまたはCSV）を標準化されたDTOに変換し、バリデーションを行います。",
  "**Process Phase** (`IProcessStrategy`): Compare validated DTO with existing data and map it to a command payload for creation or update.": "**処理フェーズ**（`IProcessStrategy`）：バリデーション済みDTOを既存データと比較し、作成または更新用のコマンドペイロードにマッピングします。",
  "Implementing Import Strategy": "インポートストラテジーの実装",
  "The import strategy handles initial transformation and validation:": "インポートストラテジーは初期変換とバリデーションを処理します：",
  "Implementing Process Strategy": "プロセスストラテジーの実装",
  "The process strategy contains core business logic for comparing and mapping data:": "プロセスストラテジーはデータの比較とマッピングのコアビジネスロジックを含みます：",
  "Module Configuration": "モジュール設定",
  "Register the ImportModule with your profiles:": "プロファイルを使用してImportModuleを登録します：",
  "Custom Event Factory for Imports": "インポート用カスタムイベントファクトリー",
  "Configure the event factory to handle import events:": "インポートイベントを処理するようにイベントファクトリーを設定します：",
  "ImportStatusHandler API": "ImportStatusHandler API",
  "The `ImportStatusHandler` is an internal event handler that manages Step Functions callbacks for import jobs. When using Step Functions orchestration (ZIP imports or STEP_FUNCTION mode CSV imports), this handler ensures proper communication with the state machine.": "`ImportStatusHandler`は、インポートジョブのStep Functionsコールバックを管理する内部イベントハンドラーです。Step Functionsオーケストレーション（ZIPインポートまたはSTEP_FUNCTIONモードのCSVインポート）を使用する場合、このハンドラーはステートマシンとの適切な通信を保証します。",
  "Behavior": "動作",
  "Import Status": "インポートステータス",
  "Action": "アクション",
  "Step Functions Command": "Step Functionsコマンド",
  "Send success callback": "成功コールバックを送信",
  "Send failure callback": "失敗コールバックを送信",
  "Other statuses": "その他のステータス",
  "Ignored": "無視",
  "None": "なし",
  "Methods": "メソッド",
  "Method": "メソッド",
  "Sends success signal to Step Functions with the import result": "インポート結果とともにStep Functionsに成功シグナルを送信",
  "Sends failure signal to Step Functions with error details": "エラー詳細とともにStep Functionsに失敗シグナルを送信",
  "Step Functions Integration": "Step Functions統合",
  "When an import job is created as part of a Step Functions workflow (e.g., ZIP import), a `taskToken` is stored in the job's attributes. The `ImportStatusHandler` listens for status change notifications and:": "Step Functionsワークフロー（例：ZIPインポート）の一部としてインポートジョブが作成されると、`taskToken`がジョブの属性に保存されます。`ImportStatusHandler`はステータス変更通知をリッスンし、以下を行います：",
  "Retrieves the import job from DynamoDB": "DynamoDBからインポートジョブを取得",
  "Checks if a `taskToken` exists in the job's attributes": "ジョブの属性に`taskToken`が存在するか確認",
  "Sends the appropriate callback based on the final status:": "最終ステータスに基づいて適切なコールバックを送信：",
  "with result data": "結果データとともに",
  "with error details": "エラー詳細とともに",
  "This ensures Step Functions workflows properly handle both success and failure cases without hanging indefinitely.": "これにより、Step Functionsワークフローが無限に待機することなく、成功と失敗の両方のケースを適切に処理できます。",
  "The `sendTaskFailure()` method was added in [version 1.0.18](./changelog#v1018) to fix an issue where Step Functions would wait indefinitely when import jobs failed. See also [Import Module Errors](./error-catalog#import-module-errors) for troubleshooting.": "`sendTaskFailure()`メソッドは[バージョン1.0.18](./changelog#v1018)で追加され、インポートジョブが失敗した際にStep Functionsが無限に待機する問題を修正しました。トラブルシューティングについては[インポートモジュールエラー](./error-catalog#import-module-errors)も参照してください。",
  "ImportQueueEventHandler Error Handling": "ImportQueueEventHandlerエラーハンドリング",
  "The `ImportQueueEventHandler` processes individual import records from the SQS queue. When an error occurs during processing (e.g., `ConditionalCheckFailedException`), the handler properly updates the parent job status.": "`ImportQueueEventHandler`はSQSキューから個々のインポートレコードを処理します。処理中にエラーが発生した場合（例：`ConditionalCheckFailedException`）、ハンドラーは親ジョブのステータスを適切に更新します。",
  "Error Flow (v1.0.19+)": "エラーフロー（v1.0.19以降）",
  "Child Job Error Occurs": "子ジョブエラー発生",
  "Mark Child Job as FAILED": "子ジョブをFAILEDとしてマーク",
  "Update Parent Job Counters": "親ジョブカウンターを更新",
  "Check if All Children Complete": "すべての子ジョブが完了したか確認",
  "Update Master": "マスターを更新",
  "more children": "",
  "FAILED": "FAILED",
  "COMPLETED": "COMPLETED",
  "ImportStatusHandler Triggered": "ImportStatusHandlerがトリガー",
  "SendTaskFailure/SendTaskSuccess": "SendTaskFailure/SendTaskSuccess",
  "Key Methods": "主要メソッド",
  "Orchestrates single import record processing with error handling": "エラーハンドリングを含む単一インポートレコード処理をオーケストレート",
  "Executes compare, map, and save lifecycle for a strategy": "ストラテジーの比較、マッピング、保存のライフサイクルを実行",
  "Error Handling Behavior": "エラーハンドリングの動作",
  "When a child import job fails:": "子インポートジョブが失敗した場合：",
  "Child job status is set to `FAILED` with error details": "子ジョブのステータスがエラー詳細とともに`FAILED`に設定される",
  "Parent job counters are atomically updated (`failedRows` incremented)": "親ジョブのカウンターがアトミックに更新される（`failedRows`がインクリメント）",
  "When all children complete, master job status is set based on results:": "すべての子ジョブが完了すると、結果に基づいてマスタージョブのステータスが設定される：",
  "If `failedRows > 0` → Master status = `FAILED`": "`failedRows > 0`の場合 → マスターステータス = `FAILED`",
  "If all succeeded → Master status = `COMPLETED`": "すべて成功した場合 → マスターステータス = `COMPLETED`",
  "Lambda does NOT crash - error is handled gracefully": "Lambdaはクラッシュしない - エラーは適切に処理される",
  "`ConditionalCheckFailedException`: This occurs when attempting to import data that already exists with conflicting version. The import job will be marked as FAILED and the parent job will properly aggregate this failure.": "`ConditionalCheckFailedException`：競合するバージョンで既に存在するデータをインポートしようとした場合に発生します。インポートジョブはFAILEDとしてマークされ、親ジョブはこの失敗を適切に集計します。",
  "Prior to v1.0.19, errors in child jobs would crash the Lambda and leave the master job in `PROCESSING` status indefinitely. The fixes in [version 1.0.19](./changelog#v1019) ensure proper error propagation and status updates.": "v1.0.19より前は、子ジョブのエラーによりLambdaがクラッシュし、マスタージョブが`PROCESSING`ステータスのまま無限に残っていました。[バージョン1.0.19](./changelog#v1019)の修正により、適切なエラー伝播とステータス更新が保証されます。",
  "CsvImportSfnEventHandler": "CsvImportSfnEventHandler",
  "The `CsvImportSfnEventHandler` handles Step Functions CSV import workflow states. It manages the `csv_loader` and `finalize_parent_job` states in the import state machine.": "`CsvImportSfnEventHandler`はStep FunctionsのCSVインポートワークフローステートを処理します。インポートステートマシン内の`csv_loader`と`finalize_parent_job`ステートを管理します。",
  "Routes events to appropriate handlers based on state name (`csv_loader` or `finalize_parent_job`)": "ステート名（`csv_loader`または`finalize_parent_job`）に基づいてイベントを適切なハンドラーにルーティング",
  "Processes the csv_loader state, creates child jobs for CSV rows": "csv_loaderステートを処理し、CSV行の子ジョブを作成します",
  "Finalizes the parent job after all children complete, sets final status": "すべての子ジョブ完了後に親ジョブを終了し、最終ステータスを設定します",
  "Status Determination (v1.0.20+)": "ステータス判定（v1.0.20以降）",
  "When finalizing the parent job, the handler correctly determines the final status:": "親ジョブを終了する際、ハンドラーは最終ステータスを正しく判定します：",
  "Correct behavior (v1.0.20+)": "正しい動作（v1.0.20以降）",
  "Any child failed → FAILED": "子ジョブが失敗した場合 → FAILED",
  "All children succeeded → COMPLETED": "すべての子ジョブが成功した場合 → COMPLETED",
  "Known Issue (Fixed in v1.0.20)": "既知の問題（v1.0.20で修正）",
  "Prior to v1.0.20, a bug in the ternary operator caused the status to always be `COMPLETED`:": "v1.0.20より前のバージョンでは、三項演算子のバグにより、ステータスが常に`COMPLETED`になっていました：",
  "Bug (pre-v1.0.20): always returned COMPLETED": "バグ（v1.0.20より前）：常にCOMPLETEDを返していた",
  "Wrong!": "間違い！",
  "This caused Step Functions to report SUCCESS even when child import jobs failed. See [version 1.0.20](./changelog#v1020) for details.": "このバグにより、子インポートジョブが失敗しても、Step FunctionsがSUCCESSを報告していました。詳細は[バージョン1.0.20](./changelog#v1020)を参照してください。",
  "ZipImportSfnEventHandler": "ZipImportSfnEventHandler",
  "The `ZipImportSfnEventHandler` handles Step Functions ZIP import workflow states. It orchestrates the processing of multiple CSV files extracted from a ZIP archive.": "`ZipImportSfnEventHandler`はStep FunctionsのZIPインポートワークフローステートを処理します。ZIPアーカイブから抽出された複数のCSVファイルの処理をオーケストレーションします。",
  "Workflow States": "ワークフローステート",
  "State": "ステート",
  "Triggers a single CSV import job for each file in the ZIP": "ZIP内の各ファイルに対して単一のCSVインポートジョブをトリガー",
  "Aggregates results from all CSV imports and finalizes the master job": "すべてのCSVインポートの結果を集計し、マスタージョブを終了",
  "Creates a CSV import job with STEP_FUNCTION mode, passing the taskToken for callback": "STEP_FUNCTIONモードでCSVインポートジョブを作成し、コールバック用のtaskTokenを渡す",
  "Aggregates results from all processed CSV files and updates the ZIP master job status": "処理されたすべてのCSVファイルの結果を集計し、ZIPマスタージョブのステータスを更新",
  "Known Issue": "既知の問題",
  "The `finalizeZipMasterJob` method currently always sets the master job status to `COMPLETED`, regardless of whether any child CSV import jobs failed. This means ZIP import workflows will report success even when individual CSV files failed to import correctly.": "`finalizeZipMasterJob`メソッドは現在、子CSVインポートジョブの失敗に関係なく、常にマスタージョブのステータスを`COMPLETED`に設定します。これは、個々のCSVファイルのインポートが失敗しても、ZIPインポートワークフローが成功を報告することを意味します。",
  "To work around this, check the `failedRows` count in the result object to determine if any errors occurred during processing.": "これを回避するには、resultオブジェクトの`failedRows`カウントを確認して、処理中にエラーが発生したかどうかを判断してください。",
  "File Naming Convention": "ファイル命名規則",
  "When processing CSV files from a ZIP archive, the handler extracts the table name from the filename:": "ZIPアーカイブからCSVファイルを処理する際、ハンドラーはファイル名からテーブル名を抽出します：",
  "Format: yyyymmddhhMMss-\\{tableName\\}.csv": "形式: yyyymmddhhMMss-\\{tableName\\}.csv",
  "Example: 20240115120000-products.csv → extracts tableName = \"products\"": "例: 20240115120000-products.csv → tableName = \"products\" を抽出",
  "If `tableName` is provided in the `CreateZipImportDto`, it overrides the extracted name.": "`CreateZipImportDto`で`tableName`が指定されている場合、抽出された名前をオーバーライドします。",
  "Processing Flow": "処理フロー",
  "ZIP File Uploaded to S3": "ZIPファイルがS3にアップロード",
  "Step Functions Triggered": "Step Functionsがトリガー",
  "Unzip and List CSV Files": "解凍してCSVファイルをリスト",
  "Map State: For Each CSV File": "Mapステート: 各CSVファイルに対して",
  "trigger_single_csv_and_wait": "trigger_single_csv_and_wait",
  "CSV Import Job Created": "CSVインポートジョブ作成",
  "(with taskToken)": "(taskToken付き)",
  "Wait for Completion": "完了を待機",
  "finalize_zip_job": "finalize_zip_job",
  "Aggregate Results & Update Master Job": "結果を集計してマスタージョブを更新",
  "ZipImportSfnEvent Structure": "ZipImportSfnEvent構造",
  "Execution ID from Step Functions": "Execution ID from Step Functions (Step Functionsからの実行ID)",
  "Step Functions context with state info": "Step Functions context with state info (ステート情報を含むStep Functionsコンテキスト)",
  "S3 key or array of results": "S3 key or array of results (S3キーまたは結果の配列)",
  "Token for callback to Step Functions": "Token for callback to Step Functions (Step Functionsへのコールバック用トークン)",
  "The `context.Execution.Input` contains:": "`context.Execution.Input`には以下が含まれます：",
  "Primary key of the ZIP master job in DynamoDB": "DynamoDBのZIPマスタージョブのプライマリキー",
  "Original import parameters (bucket, tenantCode, tableName)": "元のインポートパラメータ（bucket、tenantCode、tableName）",
  "The export patterns shown below are example implementations for your application. Unlike the import module (`@mbc-cqrs-serverless/import`), there is no dedicated export package in the framework. You can implement these patterns directly in your application code.": "以下に示すエクスポートパターンは、アプリケーション用の実装例です。インポートモジュール（`@mbc-cqrs-serverless/import`）とは異なり、フレームワークには専用のエクスポートパッケージはありません。これらのパターンをアプリケーションコードに直接実装できます。",
  "Related Documentation": "関連ドキュメント",
  "[Backend Development Guide](./backend-development) - Core backend patterns": "[バックエンド開発ガイド](./backend-development) - コアバックエンドパターン",
  "[Service Patterns](./service-patterns) - Service implementation": "[サービスパターン](./service-patterns) - サービス実装",
  "[Step Functions](./architecture/step-functions) - Workflow orchestration": "[Step Functions](./architecture/step-functions) - ワークフローオーケストレーション",
  "[Data Sync Handler Examples](./data-sync-handler-examples) - Sync handler patterns": "[データ同期ハンドラー例](./data-sync-handler-examples) - 同期ハンドラーパターン"
}