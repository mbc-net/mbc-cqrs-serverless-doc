{
  "Import": "Import",
  "A flexible and extensible module for handling data import within the MBC CQRS Serverless framework.": "A flexible and extensible module for handling data import within the MBC CQRS Serverless framework.",
  "Installation": "Installation",
  "Overview": "Overview",
  "The Import module provides a unified approach to data ingestion from multiple sources, including REST APIs and CSV files. It implements a two-phase architecture for clean separation between data ingestion and business logic execution.": "The Import module provides a unified approach to data ingestion from multiple sources, including REST APIs and CSV files. It implements a two-phase architecture for clean separation between data ingestion and business logic execution.",
  "Core Features": "Core Features",
  "Unified Architectural Design": "Unified Architectural Design",
  "Process data from REST API endpoints and CSV files through a single, consistent set of core business logic": "Process data from REST API endpoints and CSV files through a single, consistent set of core business logic",
  "Strategy Pattern": "Strategy Pattern",
  "Customize validation, transformation, and processing logic for each data entity via NestJS providers": "Customize validation, transformation, and processing logic for each data entity via NestJS providers",
  "Asynchronous Processing": "Asynchronous Processing",
  "Event-driven processing through DynamoDB Streams, SNS, and SQS for maximum scalability": "Event-driven processing through DynamoDB Streams, SNS, and SQS for maximum scalability",
  "Biphasic Processing": "Biphasic Processing",
  "Clear separation between data ingestion/validation and business logic execution": "Clear separation between data ingestion/validation and business logic execution",
  "Dual CSV Modes": "Dual CSV Modes",
  "Choose between DIRECT processing for smaller files or STEP_FUNCTION workflow for large-scale imports": "Choose between DIRECT processing for smaller files or STEP_FUNCTION workflow for large-scale imports",
  "Architecture": "Architecture",
  "The module operates on a two-phase architecture:": "The module operates on a two-phase architecture:",
  "Phase 1: Import (Ingestion)": "Phase 1: Import (Ingestion)",
  "This phase handles getting data into the system using the `IImportStrategy` interface:": "This phase handles getting data into the system using the `IImportStrategy` interface:",
  "Transform raw input (JSON body or CSV row) into a standardized, validated DTO": "Transform raw input (JSON body or CSV row) into a standardized, validated DTO",
  "Validate the transformed DTO": "Validate the transformed DTO",
  "The result is a record in a temporary DynamoDB table with CREATED status.": "The result is a record in a temporary DynamoDB table with CREATED status.",
  "Phase 2: Process (Business Logic)": "Phase 2: Process (Business Logic)",
  "Once a record is in the temporary table, an event triggers this phase using the `IProcessStrategy` interface:": "Once a record is in the temporary table, an event triggers this phase using the `IProcessStrategy` interface:",
  "Compare data with the final destination to determine status (NOT_EXIST, CHANGED, EQUAL)": "Compare data with the final destination to determine status (NOT_EXIST, CHANGED, EQUAL)",
  "Construct the final payload for create or update command": "Construct the final payload for create or update command",
  "Provide the correct CommandService to execute the write operation": "Provide the correct CommandService to execute the write operation",
  "After processing, the temporary record is updated to COMPLETED or FAILED.": "After processing, the temporary record is updated to COMPLETED or FAILED.",
  "Basic Setup": "Basic Setup",
  "Module Configuration": "Module Configuration",
  "Implementing Import Strategy": "Implementing Import Strategy",
  "Create a custom import strategy for your entity:": "Create a custom import strategy for your entity:",
  "Implementing Process Strategy": "Implementing Process Strategy",
  "Create a custom process strategy for your entity:": "Create a custom process strategy for your entity:",
  "CSV Import": "CSV Import",
  "Direct Mode": "Direct Mode",
  "For smaller CSV files, use direct processing:": "For smaller CSV files, use direct processing:",
  "Step Function Mode": "Step Function Mode",
  "For large-scale imports, use Step Function workflow:": "For large-scale imports, use Step Function workflow:",
  "REST API Import": "REST API Import",
  "Import data from REST API endpoints:": "Import data from REST API endpoints:",
  "Import Status": "Import Status",
  "Track import progress and status:": "Track import progress and status:",
  "Status": "Status",
  "Description": "Description",
  "Record created in staging table": "Record created in staging table",
  "Record is being processed": "Record is being processed",
  "Successfully processed": "Successfully processed",
  "Processing failed": "Processing failed",
  "Skipped (no changes detected)": "Skipped (no changes detected)",
  "Error Handling": "Error Handling",
  "The module provides detailed error information for failed imports:": "The module provides detailed error information for failed imports:",
  "Best Practices": "Best Practices",
  "Validation First": "Validation First",
  "Implement thorough validation in the transform phase to catch errors early": "Implement thorough validation in the transform phase to catch errors early",
  "Idempotent Processing": "Idempotent Processing",
  "Design process strategies to handle duplicate imports gracefully": "Design process strategies to handle duplicate imports gracefully",
  "Use Step Functions for Large Files": "Use Step Functions for Large Files",
  "For CSV files with thousands of rows, use STEP_FUNCTION mode": "For CSV files with thousands of rows, use STEP_FUNCTION mode",
  "Monitor Progress": "Monitor Progress",
  "Use the status tracking to monitor long-running imports": "Use the status tracking to monitor long-running imports",
  "Error Recovery": "Error Recovery",
  "Implement retry logic for transient failures": "Implement retry logic for transient failures"
}
