{
  "Learn how to implement AWS Step Functions for workflow orchestration in the MBC CQRS Serverless framework.": "Learn how to implement AWS Step Functions for workflow orchestration in the MBC CQRS Serverless framework.",
  "Step Functions": "Step Functions",
  "AWS Step Functions provides serverless workflow orchestration for coordinating distributed applications. In the MBC CQRS Serverless framework, Step Functions are used for:": "AWS Step Functions provides serverless workflow orchestration for coordinating distributed applications. In the MBC CQRS Serverless framework, Step Functions are used for:",
  "System Configuration Example": "System Configuration Example",
  "The following diagram shows how Step Functions integrate with other AWS services in a typical production environment:": "The following diagram shows how Step Functions integrate with other AWS services in a typical production environment:",
  "Data Flow Example": "Data Flow Example",
  "Here is a typical data flow for a command execution with Step Functions:": "Here is a typical data flow for a command execution with Step Functions:",
  "CDK Implementation Examples": "CDK Implementation Examples",
  "Complete Command State Machine": "Complete Command State Machine",
  "The following CDK code shows how to create a complete command handler state machine:": "The following CDK code shows how to create a complete command handler state machine:",
  "Task State Machine with Controlled Concurrency": "Task State Machine with Controlled Concurrency",
  "Distributed Map for CSV Import": "Distributed Map for CSV Import",
  "For processing large CSV files, use Distributed Map which provides native S3 integration:": "For processing large CSV files, use Distributed Map which provides native S3 integration:",
  "Event Source Configuration": "Event Source Configuration",
  "Configure DynamoDB Streams and SQS to trigger Step Functions:": "Configure DynamoDB Streams and SQS to trigger Step Functions:",
  "Long-running workflow orchestration": "Long-running workflow orchestration",
  "Saga pattern implementation for distributed transactions": "Saga pattern implementation for distributed transactions",
  "Parallel batch processing with Distributed Map": "Parallel batch processing with Distributed Map",
  "Asynchronous task coordination with callback patterns": "Asynchronous task coordination with callback patterns",
  "Architecture Overview": "Architecture Overview",
  "State Machines": "State Machines",
  "The framework provides three pre-configured state machines:": "The framework provides three pre-configured state machines:",
  "Command State Machine": "Command State Machine",
  "Handles data synchronization workflows with version control and parallel processing.": "Handles data synchronization workflows with version control and parallel processing.",
  "Key features:": "Key features:",
  "**Version checking**: Ensures command ordering and prevents conflicts": "**Version checking**: Ensures command ordering and prevents conflicts",
  "**Async callback**: Waits for previous commands using task tokens": "**Async callback**: Waits for previous commands using task tokens",
  "**Parallel sync**: Uses Map state to sync data across multiple targets": "**Parallel sync**: Uses Map state to sync data across multiple targets",
  "**TTL management**: Automatically sets expiration on records": "**TTL management**: Automatically sets expiration on records",
  "Task State Machine": "Task State Machine",
  "Executes parallel sub-tasks with controlled concurrency.": "Executes parallel sub-tasks with controlled concurrency.",
  "**Controlled concurrency**: Limits parallel executions (default: 2)": "**Controlled concurrency**: Limits parallel executions (default: 2)",
  "**Status tracking**: Real-time task status updates": "**Status tracking**: Real-time task status updates",
  "**Error handling**: Automatic failure detection and reporting": "**Error handling**: Automatic failure detection and reporting",
  "Import CSV State Machine": "Import CSV State Machine",
  "Processes large CSV files using AWS Distributed Map for massive parallelism.": "Processes large CSV files using AWS Distributed Map for massive parallelism.",
  "**S3 native integration**: Reads CSV directly from S3": "**S3 native integration**: Reads CSV directly from S3",
  "**Batch processing**: Groups rows for efficient processing": "**Batch processing**: Groups rows for efficient processing",
  "**High concurrency**: Supports up to 50 concurrent batch processors": "**High concurrency**: Supports up to 50 concurrent batch processors",
  "**EXPRESS execution**: Uses express workflows for child state machines": "**EXPRESS execution**: Uses express workflows for child state machines",
  "Implementation Guide": "Implementation Guide",
  "Step 1: Infrastructure Setup": "Step 1: Infrastructure Setup",
  "The framework automatically provisions Step Functions infrastructure using AWS CDK. Key resources include:": "The framework automatically provisions Step Functions infrastructure using AWS CDK. Key resources include:",
  "Step 2: Define Step Function Events": "Step 2: Define Step Function Events",
  "Create event classes that extend the base Step Function event:": "Create event classes that extend the base Step Function event:",
  "Step 3: Implement Event Handlers": "Step 3: Implement Event Handlers",
  "Create handlers that process Step Function events:": "Create handlers that process Step Function events:",
  "Step 4: Configure Event Factory": "Step 4: Configure Event Factory",
  "Register your Step Function events in the event factory:": "Register your Step Function events in the event factory:",
  "Step 5: Trigger State Machine Execution": "Step 5: Trigger State Machine Execution",
  "Start a state machine execution from your service:": "Start a state machine execution from your service:",
  "Use Cases": "Use Cases",
  "Use Case 1: Data Synchronization": "Use Case 1: Data Synchronization",
  "Synchronize data across multiple tables with version control and conflict resolution.": "Synchronize data across multiple tables with version control and conflict resolution.",
  "Scenario": "Scenario",
  "When a command is created, sync the data to multiple read models.": "When a command is created, sync the data to multiple read models.",
  "Use Case 2: Batch Task Processing": "Use Case 2: Batch Task Processing",
  "Execute multiple related tasks in parallel with controlled concurrency.": "Execute multiple related tasks in parallel with controlled concurrency.",
  "Process multiple items in a batch job with status tracking.": "Process multiple items in a batch job with status tracking.",
  "Use Case 3: Large-Scale CSV Import": "Use Case 3: Large-Scale CSV Import",
  "Import millions of rows from CSV files with distributed processing.": "Import millions of rows from CSV files with distributed processing.",
  "Import a large CSV file from S3 with validation and transformation.": "Import a large CSV file from S3 with validation and transformation.",
  "Use Case 4: Async Callback Pattern": "Use Case 4: Async Callback Pattern",
  "Wait for external events using task tokens.": "Wait for external events using task tokens.",
  "Wait for approval before proceeding with a workflow.": "Wait for approval before proceeding with a workflow.",
  "Callback Patterns with Task Tokens": "Callback Patterns with Task Tokens",
  "The framework implements callback patterns using AWS Step Functions task tokens for coordinating long-running workflows and waiting for external events.": "The framework implements callback patterns using AWS Step Functions task tokens for coordinating long-running workflows and waiting for external events.",
  "How Callback Patterns Work": "How Callback Patterns Work",
  "When a Step Function state uses the `WAIT_FOR_TASK_TOKEN` integration pattern, the execution pauses until an external process sends a success or failure response with the task token.": "When a Step Function state uses the `WAIT_FOR_TASK_TOKEN` integration pattern, the execution pauses until an external process sends a success or failure response with the task token.",
  "StepFunctionService Implementation": "StepFunctionService Implementation",
  "The `StepFunctionService` provides methods for starting executions and resuming paused workflows:": "The `StepFunctionService` provides methods for starting executions and resuming paused workflows:",
  "Start a new state machine execution": "Start a new state machine execution",
  "Resume a paused execution using task token": "Resume a paused execution using task token",
  "Wrap output in the expected format for Lambda integration": "Wrap output in the expected format for Lambda integration",
  "Version-Based Command Chaining": "Version-Based Command Chaining",
  "The command state machine uses callback patterns to ensure commands are processed in version order:": "The command state machine uses callback patterns to ensure commands are processed in version order:",
  "Wait for previous command to complete using task token": "Wait for previous command to complete using task token",
  "Store task token in DynamoDB for later callback": "Store task token in DynamoDB for later callback",
  "When a command finishes, check if next version is waiting": "When a command finishes, check if next version is waiting",
  "No next command, chain ends": "No next command, chain ends",
  "Resume the waiting command": "Resume the waiting command",
  "CDK Configuration for Callback Pattern": "CDK Configuration for Callback Pattern",
  "Configure the state to wait for task token in your CDK stack:": "Configure the state to wait for task token in your CDK stack:",
  "Create a state that waits for callback": "Create a state that waits for callback",
  "Include task token in payload": "Include task token in payload",
  "Use WAIT_FOR_TASK_TOKEN integration pattern": "Use WAIT_FOR_TASK_TOKEN integration pattern",
  "Long-Running Workflow Strategies": "Long-Running Workflow Strategies",
  "The framework provides several strategies for handling long-running workflows:": "The framework provides several strategies for handling long-running workflows:",
  "ZIP Import Orchestration": "ZIP Import Orchestration",
  "For complex multi-file imports, the framework uses a hierarchical orchestration pattern:": "For complex multi-file imports, the framework uses a hierarchical orchestration pattern:",
  "Task Token Propagation for Child Workflows": "Task Token Propagation for Child Workflows",
  "When triggering child workflows, the parent stores the task token for later callback:": "When triggering child workflows, the parent stores the task token for later callback:",
  "Trigger a child CSV job and wait for completion": "Trigger a child CSV job and wait for completion",
  "Task token from parent workflow": "Task token from parent workflow",
  "Create CSV job with stored task token": "Create CSV job with stored task token",
  "Store for callback when CSV processing completes": "Store for callback when CSV processing completes",
  "Workflow Timeout Configuration": "Workflow Timeout Configuration",
  "Set appropriate timeouts for long-running workflows:": "Set appropriate timeouts for long-running workflows:",
  "Overall workflow timeout": "Overall workflow timeout",
  "Integration with Import/Export Patterns": "Integration with Import/Export Patterns",
  "The framework integrates Step Functions with the import module for scalable data processing:": "The framework integrates Step Functions with the import module for scalable data processing:",
  "CSV Import Flow": "CSV Import Flow",
  "The CSV import uses a two-phase approach with Step Functions:": "The CSV import uses a two-phase approach with Step Functions:",
  "Phase 1: Create import job and trigger Step Function": "Phase 1: Create import job and trigger Step Function",
  "Process directly in Lambda (for small files)": "Process directly in Lambda (for small files)",
  "Create job and let Step Function handle processing": "Create job and let Step Function handle processing",
  "Phase 2: Step Function handler processes rows": "Phase 2: Step Function handler processes rows",
  "Count total rows and initialize job": "Count total rows and initialize job",
  "Process batch of rows": "Process batch of rows",
  "Progress Tracking with Atomic Counters": "Progress Tracking with Atomic Counters",
  "The import service uses atomic DynamoDB counters for accurate progress tracking:": "The import service uses atomic DynamoDB counters for accurate progress tracking:",
  "Atomically increment progress counters": "Atomically increment progress counters",
  "Use atomic update expression": "Use atomic update expression",
  "Check if job is complete and update final status": "Check if job is complete and update final status",
  "Processing Mode Selection": "Processing Mode Selection",
  "Choose the appropriate processing mode based on data size:": "Choose the appropriate processing mode based on data size:",
  "Processing Mode": "Processing Mode",
  "Use Case": "Use Case",
  "Max Rows": "Max Rows",
  "Concurrency": "Concurrency",
  "Small files, immediate feedback": "Small files, immediate feedback",
  "Single Lambda": "Single Lambda",
  "Large files, background processing": "Large files, background processing",
  "Millions": "Millions",
  "Up to 50": "Up to 50",
  "Example: Selecting processing mode based on file size": "Example: Selecting processing mode based on file size",
  "Step Functions Context": "Step Functions Context",
  "Every Step Function event includes context information about the execution:": "Every Step Function event includes context information about the execution:",
  "Error Handling": "Error Handling",
  "Implement robust error handling in your state machines:": "Implement robust error handling in your state machines:",
  "Handler-Level Error Handling": "Handler-Level Error Handling",
  "The framework provides built-in error handling patterns for Step Function handlers:": "The framework provides built-in error handling patterns for Step Function handlers:",
  "Command event handler with status tracking and error handling": "Command event handler with status tracking and error handling",
  "Update status to STARTED before processing": "Update status to STARTED before processing",
  "Update status to FINISHED on success": "Update status to FINISHED on success",
  "Update status to FAILED and publish alarm on error": "Update status to FAILED and publish alarm on error",
  "Task Error Handling with Continuation": "Task Error Handling with Continuation",
  "For task handlers, the framework supports continuing execution even after errors:": "For task handlers, the framework supports continuing execution even after errors:",
  "Task handler with error handling that allows workflow continuation": "Task handler with error handling that allows workflow continuation",
  "Update status to COMPLETED on success": "Update status to COMPLETED on success",
  "Update status to FAILED and publish alarm, but don't throw": "Update status to FAILED and publish alarm, but don't throw",
  "Note: Error is not re-thrown to allow Step Function to continue": "Note: Error is not re-thrown to allow Step Function to continue",
  "Uncomment to fail the entire workflow on error": "Uncomment to fail the entire workflow on error",
  "Alarm Publishing": "Alarm Publishing",
  "The framework publishes alarms to SNS for monitoring and alerting:": "The framework publishes alarms to SNS for monitoring and alerting:",
  "Publish alarm notification to SNS topic": "Publish alarm notification to SNS topic",
  "State machine error handling configuration:": "State machine error handling configuration:",
  "Best Practices": "Best Practices",
  "Design Principles": "Design Principles",
  "**Idempotency**: Design each state to be safely retryable": "**Idempotency**: Design each state to be safely retryable",
  "**Single Responsibility**: Each state should do one thing well": "**Single Responsibility**: Each state should do one thing well",
  "**Timeout Configuration**: Set appropriate timeouts for each state": "**Timeout Configuration**: Set appropriate timeouts for each state",
  "**Logging**: Enable comprehensive logging for debugging": "**Logging**: Enable comprehensive logging for debugging",
  "Performance Optimization": "Performance Optimization",
  "**Use Express Workflows**: For high-volume, short-duration workflows": "**Use Express Workflows**: For high-volume, short-duration workflows",
  "**Batch Processing**: Group items to reduce state transitions": "**Batch Processing**: Group items to reduce state transitions",
  "**Concurrency Limits**: Set appropriate limits to prevent throttling": "**Concurrency Limits**: Set appropriate limits to prevent throttling",
  "**S3 Integration**: Use native S3 integration for large data processing": "**S3 Integration**: Use native S3 integration for large data processing",
  "Monitoring": "Monitoring",
  "**CloudWatch Metrics**: Monitor execution counts, failures, and duration": "**CloudWatch Metrics**: Monitor execution counts, failures, and duration",
  "**X-Ray Tracing**: Enable distributed tracing for debugging": "**X-Ray Tracing**: Enable distributed tracing for debugging",
  "**CloudWatch Logs**: Capture detailed execution logs": "**CloudWatch Logs**: Capture detailed execution logs",
  "**Alarms**: Set up alerts for failure rates and execution times": "**Alarms**: Set up alerts for failure rates and execution times",
  "Related Documentation": "Related Documentation",
  "[Task Module](../tasks.md) - Task management with Step Functions": "[Task Module](../tasks.md) - Task management with Step Functions",
  "[Import/Export Patterns](../import-export-patterns.md) - CSV import with Distributed Map": "[Import/Export Patterns](../import-export-patterns.md) - CSV import with Distributed Map",
  "[Event Sourcing](./event-sourcing.md) - Event-driven architecture": "[Event Sourcing](./event-sourcing.md) - Event-driven architecture",
  "[CQRS Flow](./cqrs-flow.md) - Command and query separation": "[CQRS Flow](./cqrs-flow.md) - Command and query separation"
}
